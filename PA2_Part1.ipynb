{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All library l need for this assignment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.1 Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Romance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>986264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1379182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361748</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4175888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    imdbId  Action  Adventure  Animation  Comedy  Drama  Horror  Romance\n",
       "0   986264       0          0          0       0      1       0        0\n",
       "1  1379182       0          0          0       0      1       0        0\n",
       "2   361748       0          1          0       0      1       0        0\n",
       "3  4175888       0          0          0       0      0       1        0\n",
       "4   284445       1          1          0       0      0       1        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './pa2_data/part1_data/train.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop([2541, 3554, 4303, 4713, 5718, 9495]) # exclude grayscale pictures\n",
    "df.index = range(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10365 images\n",
    "file = df['imdbId']\n",
    "\n",
    "file = [str(i)+\".jpg\" for i in file]\n",
    "file = [os.path.join(\"./pa2_data/part1_data/images\", i) for i in file ]\n",
    "\n",
    "label = np.array(df[['Action', 'Adventure', 'Animation', 'Comedy', 'Drama',\n",
    "       'Horror', 'Romance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(32),\n",
    "     transforms.ToTensor(),    # range [0, 255] -> [0.0,1.0]\n",
    "     transforms.Normalize((0.5,), (0.5,))])   # channel=（channel-mean）/std  -> [-1, 1]\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    \n",
    "    img_pil =  Image.open(path) \n",
    "    img_tensor = transform(img_pil)\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MovieDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file, label, loader=default_loader):\n",
    "        \n",
    "        self.images = file\n",
    "        self.target = label\n",
    "        self.loader = loader\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        fn = self.images[idx]\n",
    "        img = self.loader(fn)\n",
    "        \n",
    "        target = self.target[idx]\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df)):\n",
    "#    if default_loader(file[i]).size()[0] != 3:\n",
    "#        print(i)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train set and validation set\n",
    "\n",
    "full_data = MovieDataset(file, label)\n",
    "\n",
    "train_size = int(0.8 * len(full_data))\n",
    "validation_size = len(full_data) - train_size\n",
    "\n",
    "train, validation = random_split(full_data, [train_size, validation_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.2 CNN Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=1)\n",
    "\n",
    "valid_loader = DataLoader(validation, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "inputs, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the posters \n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 43, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 21, 14]               0\n",
      "            Conv2d-3            [-1, 16, 10, 7]             400\n",
      "         MaxPool2d-4             [-1, 16, 5, 3]               0\n",
      "       BatchNorm1d-5                  [-1, 240]             480\n",
      "            Linear-6                  [-1, 128]          30,848\n",
      "           Dropout-7                  [-1, 128]               0\n",
      "       BatchNorm1d-8                  [-1, 128]             256\n",
      "            Linear-9                   [-1, 80]          10,320\n",
      "          Dropout-10                   [-1, 80]               0\n",
      "      BatchNorm1d-11                   [-1, 80]             160\n",
      "           Linear-12                    [-1, 7]             567\n",
      "================================================================\n",
      "Total params: 43,487\n",
      "Trainable params: 43,487\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torchsummary is not available in conda install, \n",
    "# you need to install using pip\n",
    "#!pip install torchsummary\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 5, padding = 0, stride = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 2, padding = 0, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*3, 128)\n",
    "        self.fc2 = nn.Linear(128, 80)\n",
    "        self.fc3 = nn.Linear(80, 7)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(16*5*3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(80)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Three Conv2d layers\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6, 21, 14\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 16, 5, 3\n",
    "\n",
    "        x = x.view(-1, 16*5*3)\n",
    "        # 3 BatchNorm1d and 2 dropouts\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.drops(x)\n",
    "        \n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.drops(x)\n",
    "        \n",
    "        x = self.bn3(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## gpu or cpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "\n",
    "summary(model, input_size=(3, 47, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/pa2_part1')\n",
    "\n",
    "# add graph\n",
    "writer.add_graph(model, inputs)\n",
    "writer.close()\n",
    "\n",
    "# run tensorboard --logdir='./runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [20/5530], Train Loss: 0.7154, Valid Loss: 0.7051\n",
      "Epoch [1/10], Step [40/5530], Train Loss: 0.6891, Valid Loss: 0.6892\n",
      "Epoch [1/10], Step [60/5530], Train Loss: 0.6740, Valid Loss: 0.6694\n",
      "Epoch [1/10], Step [80/5530], Train Loss: 0.6619, Valid Loss: 0.6486\n",
      "Epoch [1/10], Step [100/5530], Train Loss: 0.6461, Valid Loss: 0.6340\n",
      "Epoch [1/10], Step [120/5530], Train Loss: 0.6293, Valid Loss: 0.6079\n",
      "Epoch [1/10], Step [140/5530], Train Loss: 0.6029, Valid Loss: 0.5900\n",
      "Epoch [1/10], Step [160/5530], Train Loss: 0.5888, Valid Loss: 0.5645\n",
      "Epoch [1/10], Step [180/5530], Train Loss: 0.5558, Valid Loss: 0.5463\n",
      "Epoch [1/10], Step [200/5530], Train Loss: 0.5438, Valid Loss: 0.5258\n",
      "Epoch [1/10], Step [220/5530], Train Loss: 0.5184, Valid Loss: 0.5103\n",
      "Epoch [1/10], Step [240/5530], Train Loss: 0.5128, Valid Loss: 0.4911\n",
      "Epoch [1/10], Step [260/5530], Train Loss: 0.4968, Valid Loss: 0.4810\n",
      "Epoch [1/10], Step [280/5530], Train Loss: 0.4977, Valid Loss: 0.4803\n",
      "Epoch [1/10], Step [300/5530], Train Loss: 0.4951, Valid Loss: 0.4750\n",
      "Epoch [1/10], Step [320/5530], Train Loss: 0.4996, Valid Loss: 0.4734\n",
      "Epoch [1/10], Step [340/5530], Train Loss: 0.4971, Valid Loss: 0.4712\n",
      "Epoch [1/10], Step [360/5530], Train Loss: 0.4625, Valid Loss: 0.4671\n",
      "Epoch [1/10], Step [380/5530], Train Loss: 0.4551, Valid Loss: 0.4677\n",
      "Epoch [1/10], Step [400/5530], Train Loss: 0.4767, Valid Loss: 0.4671\n",
      "Epoch [1/10], Step [420/5530], Train Loss: 0.4945, Valid Loss: 0.4678\n",
      "Epoch [1/10], Step [440/5530], Train Loss: 0.4705, Valid Loss: 0.4668\n",
      "Epoch [1/10], Step [460/5530], Train Loss: 0.4822, Valid Loss: 0.4670\n",
      "Epoch [1/10], Step [480/5530], Train Loss: 0.4860, Valid Loss: 0.4673\n",
      "Epoch [1/10], Step [500/5530], Train Loss: 0.4579, Valid Loss: 0.4670\n",
      "Epoch [1/10], Step [520/5530], Train Loss: 0.5027, Valid Loss: 0.4668\n",
      "Epoch [1/10], Step [540/5530], Train Loss: 0.4739, Valid Loss: 0.4649\n",
      "Epoch [2/10], Step [560/5530], Train Loss: 0.4842, Valid Loss: 0.4654\n",
      "Epoch [2/10], Step [580/5530], Train Loss: 0.4711, Valid Loss: 0.4692\n",
      "Epoch [2/10], Step [600/5530], Train Loss: 0.4865, Valid Loss: 0.4669\n",
      "Epoch [2/10], Step [620/5530], Train Loss: 0.4956, Valid Loss: 0.4637\n",
      "Epoch [2/10], Step [640/5530], Train Loss: 0.4664, Valid Loss: 0.4614\n",
      "Epoch [2/10], Step [660/5530], Train Loss: 0.4676, Valid Loss: 0.4616\n",
      "Epoch [2/10], Step [680/5530], Train Loss: 0.4744, Valid Loss: 0.4690\n",
      "Epoch [2/10], Step [700/5530], Train Loss: 0.4559, Valid Loss: 0.4645\n",
      "Epoch [2/10], Step [720/5530], Train Loss: 0.4496, Valid Loss: 0.4639\n",
      "Epoch [2/10], Step [740/5530], Train Loss: 0.4821, Valid Loss: 0.4628\n",
      "Epoch [2/10], Step [760/5530], Train Loss: 0.4636, Valid Loss: 0.4630\n",
      "Epoch [2/10], Step [780/5530], Train Loss: 0.4648, Valid Loss: 0.4657\n",
      "Epoch [2/10], Step [800/5530], Train Loss: 0.4826, Valid Loss: 0.4622\n",
      "Epoch [2/10], Step [820/5530], Train Loss: 0.4646, Valid Loss: 0.4631\n",
      "Epoch [2/10], Step [840/5530], Train Loss: 0.4570, Valid Loss: 0.4615\n",
      "Epoch [2/10], Step [860/5530], Train Loss: 0.4616, Valid Loss: 0.4605\n",
      "Epoch [2/10], Step [880/5530], Train Loss: 0.4803, Valid Loss: 0.4601\n",
      "Epoch [2/10], Step [900/5530], Train Loss: 0.4732, Valid Loss: 0.4580\n",
      "Epoch [2/10], Step [920/5530], Train Loss: 0.4693, Valid Loss: 0.4617\n",
      "Epoch [2/10], Step [940/5530], Train Loss: 0.4932, Valid Loss: 0.4603\n",
      "Epoch [2/10], Step [960/5530], Train Loss: 0.4733, Valid Loss: 0.4597\n",
      "Epoch [2/10], Step [980/5530], Train Loss: 0.4745, Valid Loss: 0.4603\n",
      "Epoch [2/10], Step [1000/5530], Train Loss: 0.4705, Valid Loss: 0.4577\n",
      "Epoch [2/10], Step [1020/5530], Train Loss: 0.4893, Valid Loss: 0.4598\n",
      "Epoch [2/10], Step [1040/5530], Train Loss: 0.4506, Valid Loss: 0.4614\n",
      "Epoch [2/10], Step [1060/5530], Train Loss: 0.4540, Valid Loss: 0.4600\n",
      "Epoch [2/10], Step [1080/5530], Train Loss: 0.4665, Valid Loss: 0.4584\n",
      "Epoch [2/10], Step [1100/5530], Train Loss: 0.4660, Valid Loss: 0.4613\n",
      "Epoch [3/10], Step [1120/5530], Train Loss: 0.4454, Valid Loss: 0.4590\n",
      "Epoch [3/10], Step [1140/5530], Train Loss: 0.4550, Valid Loss: 0.4581\n",
      "Epoch [3/10], Step [1160/5530], Train Loss: 0.4685, Valid Loss: 0.4587\n",
      "Epoch [3/10], Step [1180/5530], Train Loss: 0.4790, Valid Loss: 0.4566\n",
      "Epoch [3/10], Step [1200/5530], Train Loss: 0.4736, Valid Loss: 0.4614\n",
      "Epoch [3/10], Step [1220/5530], Train Loss: 0.4721, Valid Loss: 0.4582\n",
      "Epoch [3/10], Step [1240/5530], Train Loss: 0.4573, Valid Loss: 0.4594\n",
      "Epoch [3/10], Step [1260/5530], Train Loss: 0.4528, Valid Loss: 0.4606\n",
      "Epoch [3/10], Step [1280/5530], Train Loss: 0.4554, Valid Loss: 0.4628\n",
      "Epoch [3/10], Step [1300/5530], Train Loss: 0.4509, Valid Loss: 0.4581\n",
      "Epoch [3/10], Step [1320/5530], Train Loss: 0.4716, Valid Loss: 0.4567\n",
      "Epoch [3/10], Step [1340/5530], Train Loss: 0.4770, Valid Loss: 0.4593\n",
      "Epoch [3/10], Step [1360/5530], Train Loss: 0.4839, Valid Loss: 0.4582\n",
      "Epoch [3/10], Step [1380/5530], Train Loss: 0.4825, Valid Loss: 0.4598\n",
      "Epoch [3/10], Step [1400/5530], Train Loss: 0.4766, Valid Loss: 0.4573\n",
      "Epoch [3/10], Step [1420/5530], Train Loss: 0.4693, Valid Loss: 0.4562\n",
      "Epoch [3/10], Step [1440/5530], Train Loss: 0.4393, Valid Loss: 0.4563\n",
      "Epoch [3/10], Step [1460/5530], Train Loss: 0.4585, Valid Loss: 0.4550\n",
      "Epoch [3/10], Step [1480/5530], Train Loss: 0.4543, Valid Loss: 0.4561\n",
      "Epoch [3/10], Step [1500/5530], Train Loss: 0.4495, Valid Loss: 0.4583\n",
      "Epoch [3/10], Step [1520/5530], Train Loss: 0.4424, Valid Loss: 0.4532\n",
      "Epoch [3/10], Step [1540/5530], Train Loss: 0.4397, Valid Loss: 0.4554\n",
      "Epoch [3/10], Step [1560/5530], Train Loss: 0.4479, Valid Loss: 0.4555\n",
      "Epoch [3/10], Step [1580/5530], Train Loss: 0.4733, Valid Loss: 0.4585\n",
      "Epoch [3/10], Step [1600/5530], Train Loss: 0.4735, Valid Loss: 0.4553\n",
      "Epoch [3/10], Step [1620/5530], Train Loss: 0.4663, Valid Loss: 0.4560\n",
      "Epoch [3/10], Step [1640/5530], Train Loss: 0.4567, Valid Loss: 0.4565\n",
      "Epoch [4/10], Step [1660/5530], Train Loss: 0.4724, Valid Loss: 0.4572\n",
      "Epoch [4/10], Step [1680/5530], Train Loss: 0.4574, Valid Loss: 0.4536\n",
      "Epoch [4/10], Step [1700/5530], Train Loss: 0.4447, Valid Loss: 0.4555\n",
      "Epoch [4/10], Step [1720/5530], Train Loss: 0.4608, Valid Loss: 0.4548\n",
      "Epoch [4/10], Step [1740/5530], Train Loss: 0.4464, Valid Loss: 0.4536\n",
      "Epoch [4/10], Step [1760/5530], Train Loss: 0.4563, Valid Loss: 0.4534\n",
      "Epoch [4/10], Step [1780/5530], Train Loss: 0.4337, Valid Loss: 0.4551\n",
      "Epoch [4/10], Step [1800/5530], Train Loss: 0.4718, Valid Loss: 0.4558\n",
      "Epoch [4/10], Step [1820/5530], Train Loss: 0.4687, Valid Loss: 0.4528\n",
      "Epoch [4/10], Step [1840/5530], Train Loss: 0.4491, Valid Loss: 0.4540\n",
      "Epoch [4/10], Step [1860/5530], Train Loss: 0.4577, Valid Loss: 0.4548\n",
      "Epoch [4/10], Step [1880/5530], Train Loss: 0.4519, Valid Loss: 0.4527\n",
      "Epoch [4/10], Step [1900/5530], Train Loss: 0.4562, Valid Loss: 0.4552\n",
      "Epoch [4/10], Step [1920/5530], Train Loss: 0.4639, Valid Loss: 0.4512\n",
      "Epoch [4/10], Step [1940/5530], Train Loss: 0.4650, Valid Loss: 0.4561\n",
      "Epoch [4/10], Step [1960/5530], Train Loss: 0.4403, Valid Loss: 0.4538\n",
      "Epoch [4/10], Step [1980/5530], Train Loss: 0.4623, Valid Loss: 0.4540\n",
      "Epoch [4/10], Step [2000/5530], Train Loss: 0.4578, Valid Loss: 0.4537\n",
      "Epoch [4/10], Step [2020/5530], Train Loss: 0.4584, Valid Loss: 0.4537\n",
      "Epoch [4/10], Step [2040/5530], Train Loss: 0.4845, Valid Loss: 0.4512\n",
      "Epoch [4/10], Step [2060/5530], Train Loss: 0.4630, Valid Loss: 0.4572\n",
      "Epoch [4/10], Step [2080/5530], Train Loss: 0.4837, Valid Loss: 0.4551\n",
      "Epoch [4/10], Step [2100/5530], Train Loss: 0.4683, Valid Loss: 0.4536\n",
      "Epoch [4/10], Step [2120/5530], Train Loss: 0.4325, Valid Loss: 0.4552\n",
      "Epoch [4/10], Step [2140/5530], Train Loss: 0.4667, Valid Loss: 0.4518\n",
      "Epoch [4/10], Step [2160/5530], Train Loss: 0.4458, Valid Loss: 0.4518\n",
      "Epoch [4/10], Step [2180/5530], Train Loss: 0.4473, Valid Loss: 0.4549\n",
      "Epoch [4/10], Step [2200/5530], Train Loss: 0.4593, Valid Loss: 0.4534\n",
      "Epoch [5/10], Step [2220/5530], Train Loss: 0.4533, Valid Loss: 0.4559\n",
      "Epoch [5/10], Step [2240/5530], Train Loss: 0.4627, Valid Loss: 0.4555\n",
      "Epoch [5/10], Step [2260/5530], Train Loss: 0.4521, Valid Loss: 0.4541\n",
      "Epoch [5/10], Step [2280/5530], Train Loss: 0.4477, Valid Loss: 0.4533\n",
      "Epoch [5/10], Step [2300/5530], Train Loss: 0.4744, Valid Loss: 0.4555\n",
      "Epoch [5/10], Step [2320/5530], Train Loss: 0.4572, Valid Loss: 0.4547\n",
      "Epoch [5/10], Step [2340/5530], Train Loss: 0.4600, Valid Loss: 0.4566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [2360/5530], Train Loss: 0.4614, Valid Loss: 0.4702\n",
      "Epoch [5/10], Step [2380/5530], Train Loss: 0.4605, Valid Loss: 0.4584\n",
      "Epoch [5/10], Step [2400/5530], Train Loss: 0.4712, Valid Loss: 0.4533\n",
      "Epoch [5/10], Step [2420/5530], Train Loss: 0.4254, Valid Loss: 0.4542\n",
      "Epoch [5/10], Step [2440/5530], Train Loss: 0.4355, Valid Loss: 0.4546\n",
      "Epoch [5/10], Step [2460/5530], Train Loss: 0.4408, Valid Loss: 0.4546\n",
      "Epoch [5/10], Step [2480/5530], Train Loss: 0.4539, Valid Loss: 0.4558\n",
      "Epoch [5/10], Step [2500/5530], Train Loss: 0.4484, Valid Loss: 0.4550\n",
      "Epoch [5/10], Step [2520/5530], Train Loss: 0.4496, Valid Loss: 0.4550\n",
      "Epoch [5/10], Step [2540/5530], Train Loss: 0.4594, Valid Loss: 0.4562\n",
      "Epoch [5/10], Step [2560/5530], Train Loss: 0.4510, Valid Loss: 0.4537\n",
      "Epoch [5/10], Step [2580/5530], Train Loss: 0.4598, Valid Loss: 0.4545\n",
      "Epoch [5/10], Step [2600/5530], Train Loss: 0.4643, Valid Loss: 0.4516\n",
      "Epoch [5/10], Step [2620/5530], Train Loss: 0.4487, Valid Loss: 0.4539\n",
      "Epoch [5/10], Step [2640/5530], Train Loss: 0.4678, Valid Loss: 0.4560\n",
      "Epoch [5/10], Step [2660/5530], Train Loss: 0.4536, Valid Loss: 0.4590\n",
      "Epoch [5/10], Step [2680/5530], Train Loss: 0.4673, Valid Loss: 0.4544\n",
      "Epoch [5/10], Step [2700/5530], Train Loss: 0.4538, Valid Loss: 0.4518\n",
      "Epoch [5/10], Step [2720/5530], Train Loss: 0.4604, Valid Loss: 0.4554\n",
      "Epoch [5/10], Step [2740/5530], Train Loss: 0.4633, Valid Loss: 0.4556\n",
      "Epoch [5/10], Step [2760/5530], Train Loss: 0.4737, Valid Loss: 0.4586\n",
      "Epoch [6/10], Step [2780/5530], Train Loss: 0.4443, Valid Loss: 0.4543\n",
      "Epoch [6/10], Step [2800/5530], Train Loss: 0.4461, Valid Loss: 0.4548\n",
      "Epoch [6/10], Step [2820/5530], Train Loss: 0.4623, Valid Loss: 0.4515\n",
      "Epoch [6/10], Step [2840/5530], Train Loss: 0.4425, Valid Loss: 0.4518\n",
      "Epoch [6/10], Step [2860/5530], Train Loss: 0.4675, Valid Loss: 0.4535\n",
      "Epoch [6/10], Step [2880/5530], Train Loss: 0.4501, Valid Loss: 0.4513\n",
      "Epoch [6/10], Step [2900/5530], Train Loss: 0.4532, Valid Loss: 0.4521\n",
      "Epoch [6/10], Step [2920/5530], Train Loss: 0.4518, Valid Loss: 0.4531\n",
      "Epoch [6/10], Step [2940/5530], Train Loss: 0.4314, Valid Loss: 0.4522\n",
      "Epoch [6/10], Step [2960/5530], Train Loss: 0.4538, Valid Loss: 0.4528\n",
      "Epoch [6/10], Step [2980/5530], Train Loss: 0.4475, Valid Loss: 0.4501\n",
      "Epoch [6/10], Step [3000/5530], Train Loss: 0.4592, Valid Loss: 0.4513\n",
      "Epoch [6/10], Step [3020/5530], Train Loss: 0.4598, Valid Loss: 0.4535\n",
      "Epoch [6/10], Step [3040/5530], Train Loss: 0.4341, Valid Loss: 0.4578\n",
      "Epoch [6/10], Step [3060/5530], Train Loss: 0.4469, Valid Loss: 0.4543\n",
      "Epoch [6/10], Step [3080/5530], Train Loss: 0.4660, Valid Loss: 0.4542\n",
      "Epoch [6/10], Step [3100/5530], Train Loss: 0.4539, Valid Loss: 0.4523\n",
      "Epoch [6/10], Step [3120/5530], Train Loss: 0.4654, Valid Loss: 0.4519\n",
      "Epoch [6/10], Step [3140/5530], Train Loss: 0.4601, Valid Loss: 0.4550\n",
      "Epoch [6/10], Step [3160/5530], Train Loss: 0.4510, Valid Loss: 0.4533\n",
      "Epoch [6/10], Step [3180/5530], Train Loss: 0.4235, Valid Loss: 0.4512\n",
      "Epoch [6/10], Step [3200/5530], Train Loss: 0.4581, Valid Loss: 0.4507\n",
      "Epoch [6/10], Step [3220/5530], Train Loss: 0.4694, Valid Loss: 0.4570\n",
      "Epoch [6/10], Step [3240/5530], Train Loss: 0.4479, Valid Loss: 0.4539\n",
      "Epoch [6/10], Step [3260/5530], Train Loss: 0.4712, Valid Loss: 0.4521\n",
      "Epoch [6/10], Step [3280/5530], Train Loss: 0.4478, Valid Loss: 0.4533\n",
      "Epoch [6/10], Step [3300/5530], Train Loss: 0.4662, Valid Loss: 0.4527\n",
      "Epoch [7/10], Step [3320/5530], Train Loss: 0.4512, Valid Loss: 0.4504\n",
      "Epoch [7/10], Step [3340/5530], Train Loss: 0.4629, Valid Loss: 0.4533\n",
      "Epoch [7/10], Step [3360/5530], Train Loss: 0.4433, Valid Loss: 0.4548\n",
      "Epoch [7/10], Step [3380/5530], Train Loss: 0.4486, Valid Loss: 0.4534\n",
      "Epoch [7/10], Step [3400/5530], Train Loss: 0.4473, Valid Loss: 0.4546\n",
      "Epoch [7/10], Step [3420/5530], Train Loss: 0.4402, Valid Loss: 0.4535\n",
      "Epoch [7/10], Step [3440/5530], Train Loss: 0.4490, Valid Loss: 0.4508\n",
      "Epoch [7/10], Step [3460/5530], Train Loss: 0.4373, Valid Loss: 0.4539\n",
      "Epoch [7/10], Step [3480/5530], Train Loss: 0.4746, Valid Loss: 0.4536\n",
      "Epoch [7/10], Step [3500/5530], Train Loss: 0.4648, Valid Loss: 0.4542\n",
      "Epoch [7/10], Step [3520/5530], Train Loss: 0.4667, Valid Loss: 0.4530\n",
      "Epoch [7/10], Step [3540/5530], Train Loss: 0.4558, Valid Loss: 0.4498\n",
      "Epoch [7/10], Step [3560/5530], Train Loss: 0.4647, Valid Loss: 0.4510\n",
      "Epoch [7/10], Step [3580/5530], Train Loss: 0.4501, Valid Loss: 0.4531\n",
      "Epoch [7/10], Step [3600/5530], Train Loss: 0.4497, Valid Loss: 0.4510\n",
      "Epoch [7/10], Step [3620/5530], Train Loss: 0.4502, Valid Loss: 0.4515\n",
      "Epoch [7/10], Step [3640/5530], Train Loss: 0.4611, Valid Loss: 0.4510\n",
      "Epoch [7/10], Step [3660/5530], Train Loss: 0.4625, Valid Loss: 0.4512\n",
      "Epoch [7/10], Step [3680/5530], Train Loss: 0.4534, Valid Loss: 0.4502\n",
      "Epoch [7/10], Step [3700/5530], Train Loss: 0.4528, Valid Loss: 0.4524\n",
      "Epoch [7/10], Step [3720/5530], Train Loss: 0.4436, Valid Loss: 0.4479\n",
      "Epoch [7/10], Step [3740/5530], Train Loss: 0.4582, Valid Loss: 0.4522\n",
      "Epoch [7/10], Step [3760/5530], Train Loss: 0.4366, Valid Loss: 0.4539\n",
      "Epoch [7/10], Step [3780/5530], Train Loss: 0.4399, Valid Loss: 0.4526\n",
      "Epoch [7/10], Step [3800/5530], Train Loss: 0.4431, Valid Loss: 0.4512\n",
      "Epoch [7/10], Step [3820/5530], Train Loss: 0.4510, Valid Loss: 0.4524\n",
      "Epoch [7/10], Step [3840/5530], Train Loss: 0.4382, Valid Loss: 0.4523\n",
      "Epoch [7/10], Step [3860/5530], Train Loss: 0.4622, Valid Loss: 0.4501\n",
      "Epoch [8/10], Step [3880/5530], Train Loss: 0.4521, Valid Loss: 0.4486\n",
      "Epoch [8/10], Step [3900/5530], Train Loss: 0.4643, Valid Loss: 0.4495\n",
      "Epoch [8/10], Step [3920/5530], Train Loss: 0.4370, Valid Loss: 0.4498\n",
      "Epoch [8/10], Step [3940/5530], Train Loss: 0.4554, Valid Loss: 0.4522\n",
      "Epoch [8/10], Step [3960/5530], Train Loss: 0.4540, Valid Loss: 0.4507\n",
      "Epoch [8/10], Step [3980/5530], Train Loss: 0.4423, Valid Loss: 0.4542\n",
      "Epoch [8/10], Step [4000/5530], Train Loss: 0.4344, Valid Loss: 0.4516\n",
      "Epoch [8/10], Step [4020/5530], Train Loss: 0.4418, Valid Loss: 0.4497\n",
      "Epoch [8/10], Step [4040/5530], Train Loss: 0.4479, Valid Loss: 0.4503\n",
      "Epoch [8/10], Step [4060/5530], Train Loss: 0.4467, Valid Loss: 0.4517\n",
      "Epoch [8/10], Step [4080/5530], Train Loss: 0.4266, Valid Loss: 0.4534\n",
      "Epoch [8/10], Step [4100/5530], Train Loss: 0.4489, Valid Loss: 0.4526\n",
      "Epoch [8/10], Step [4120/5530], Train Loss: 0.4546, Valid Loss: 0.4515\n",
      "Epoch [8/10], Step [4140/5530], Train Loss: 0.4520, Valid Loss: 0.4529\n",
      "Epoch [8/10], Step [4160/5530], Train Loss: 0.4447, Valid Loss: 0.4494\n",
      "Epoch [8/10], Step [4180/5530], Train Loss: 0.4526, Valid Loss: 0.4501\n",
      "Epoch [8/10], Step [4200/5530], Train Loss: 0.4536, Valid Loss: 0.4532\n",
      "Epoch [8/10], Step [4220/5530], Train Loss: 0.4623, Valid Loss: 0.4513\n",
      "Epoch [8/10], Step [4240/5530], Train Loss: 0.4327, Valid Loss: 0.4485\n",
      "Epoch [8/10], Step [4260/5530], Train Loss: 0.4582, Valid Loss: 0.4535\n",
      "Epoch [8/10], Step [4280/5530], Train Loss: 0.4343, Valid Loss: 0.4487\n",
      "Epoch [8/10], Step [4300/5530], Train Loss: 0.4548, Valid Loss: 0.4484\n",
      "Epoch [8/10], Step [4320/5530], Train Loss: 0.4704, Valid Loss: 0.4506\n",
      "Epoch [8/10], Step [4340/5530], Train Loss: 0.4424, Valid Loss: 0.4488\n",
      "Epoch [8/10], Step [4360/5530], Train Loss: 0.4553, Valid Loss: 0.4485\n",
      "Epoch [8/10], Step [4380/5530], Train Loss: 0.4503, Valid Loss: 0.4519\n",
      "Epoch [8/10], Step [4400/5530], Train Loss: 0.4640, Valid Loss: 0.4499\n",
      "Epoch [8/10], Step [4420/5530], Train Loss: 0.4509, Valid Loss: 0.4483\n",
      "Epoch [9/10], Step [4440/5530], Train Loss: 0.4298, Valid Loss: 0.4480\n",
      "Epoch [9/10], Step [4460/5530], Train Loss: 0.4347, Valid Loss: 0.4496\n",
      "Epoch [9/10], Step [4480/5530], Train Loss: 0.4224, Valid Loss: 0.4495\n",
      "Epoch [9/10], Step [4500/5530], Train Loss: 0.4577, Valid Loss: 0.4504\n",
      "Epoch [9/10], Step [4520/5530], Train Loss: 0.4604, Valid Loss: 0.4498\n",
      "Epoch [9/10], Step [4540/5530], Train Loss: 0.4475, Valid Loss: 0.4502\n",
      "Epoch [9/10], Step [4560/5530], Train Loss: 0.4511, Valid Loss: 0.4476\n",
      "Epoch [9/10], Step [4580/5530], Train Loss: 0.4561, Valid Loss: 0.4494\n",
      "Epoch [9/10], Step [4600/5530], Train Loss: 0.4263, Valid Loss: 0.4510\n",
      "Epoch [9/10], Step [4620/5530], Train Loss: 0.4338, Valid Loss: 0.4512\n",
      "Epoch [9/10], Step [4640/5530], Train Loss: 0.4589, Valid Loss: 0.4485\n",
      "Epoch [9/10], Step [4660/5530], Train Loss: 0.4471, Valid Loss: 0.4485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [4680/5530], Train Loss: 0.4498, Valid Loss: 0.4480\n",
      "Epoch [9/10], Step [4700/5530], Train Loss: 0.4435, Valid Loss: 0.4480\n",
      "Epoch [9/10], Step [4720/5530], Train Loss: 0.4342, Valid Loss: 0.4472\n",
      "Epoch [9/10], Step [4740/5530], Train Loss: 0.4623, Valid Loss: 0.4473\n",
      "Epoch [9/10], Step [4760/5530], Train Loss: 0.4576, Valid Loss: 0.4509\n",
      "Epoch [9/10], Step [4780/5530], Train Loss: 0.4513, Valid Loss: 0.4495\n",
      "Epoch [9/10], Step [4800/5530], Train Loss: 0.4397, Valid Loss: 0.4573\n",
      "Epoch [9/10], Step [4820/5530], Train Loss: 0.4727, Valid Loss: 0.4487\n",
      "Epoch [9/10], Step [4840/5530], Train Loss: 0.4575, Valid Loss: 0.4496\n",
      "Epoch [9/10], Step [4860/5530], Train Loss: 0.4491, Valid Loss: 0.4482\n",
      "Epoch [9/10], Step [4880/5530], Train Loss: 0.4535, Valid Loss: 0.4517\n",
      "Epoch [9/10], Step [4900/5530], Train Loss: 0.4259, Valid Loss: 0.4509\n",
      "Epoch [9/10], Step [4920/5530], Train Loss: 0.4310, Valid Loss: 0.4496\n",
      "Epoch [9/10], Step [4940/5530], Train Loss: 0.4372, Valid Loss: 0.4494\n",
      "Epoch [9/10], Step [4960/5530], Train Loss: 0.4482, Valid Loss: 0.4504\n",
      "Epoch [10/10], Step [4980/5530], Train Loss: 0.4478, Valid Loss: 0.4492\n",
      "Epoch [10/10], Step [5000/5530], Train Loss: 0.4432, Valid Loss: 0.4503\n",
      "Epoch [10/10], Step [5020/5530], Train Loss: 0.4372, Valid Loss: 0.4511\n",
      "Epoch [10/10], Step [5040/5530], Train Loss: 0.4370, Valid Loss: 0.4477\n",
      "Epoch [10/10], Step [5060/5530], Train Loss: 0.4347, Valid Loss: 0.4510\n",
      "Epoch [10/10], Step [5080/5530], Train Loss: 0.4678, Valid Loss: 0.4474\n",
      "Epoch [10/10], Step [5100/5530], Train Loss: 0.4267, Valid Loss: 0.4515\n",
      "Epoch [10/10], Step [5120/5530], Train Loss: 0.4707, Valid Loss: 0.4538\n",
      "Epoch [10/10], Step [5140/5530], Train Loss: 0.4452, Valid Loss: 0.4515\n",
      "Epoch [10/10], Step [5160/5530], Train Loss: 0.4564, Valid Loss: 0.4497\n",
      "Epoch [10/10], Step [5180/5530], Train Loss: 0.4576, Valid Loss: 0.4506\n",
      "Epoch [10/10], Step [5200/5530], Train Loss: 0.4147, Valid Loss: 0.4541\n",
      "Epoch [10/10], Step [5220/5530], Train Loss: 0.4553, Valid Loss: 0.4498\n",
      "Epoch [10/10], Step [5240/5530], Train Loss: 0.4440, Valid Loss: 0.4477\n",
      "Epoch [10/10], Step [5260/5530], Train Loss: 0.4599, Valid Loss: 0.4523\n",
      "Epoch [10/10], Step [5280/5530], Train Loss: 0.4336, Valid Loss: 0.4501\n",
      "Epoch [10/10], Step [5300/5530], Train Loss: 0.4498, Valid Loss: 0.4519\n",
      "Epoch [10/10], Step [5320/5530], Train Loss: 0.4501, Valid Loss: 0.4541\n",
      "Epoch [10/10], Step [5340/5530], Train Loss: 0.4384, Valid Loss: 0.4511\n",
      "Epoch [10/10], Step [5360/5530], Train Loss: 0.4310, Valid Loss: 0.4513\n",
      "Epoch [10/10], Step [5380/5530], Train Loss: 0.4471, Valid Loss: 0.4499\n",
      "Epoch [10/10], Step [5400/5530], Train Loss: 0.4522, Valid Loss: 0.4488\n",
      "Epoch [10/10], Step [5420/5530], Train Loss: 0.4535, Valid Loss: 0.4531\n",
      "Epoch [10/10], Step [5440/5530], Train Loss: 0.4477, Valid Loss: 0.4477\n",
      "Epoch [10/10], Step [5460/5530], Train Loss: 0.4497, Valid Loss: 0.4499\n",
      "Epoch [10/10], Step [5480/5530], Train Loss: 0.4645, Valid Loss: 0.4507\n",
      "Epoch [10/10], Step [5500/5530], Train Loss: 0.4406, Valid Loss: 0.4476\n",
      "Epoch [10/10], Step [5520/5530], Train Loss: 0.4445, Valid Loss: 0.4518\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "global_step = 0\n",
    "eval_every = 20\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "total_step = len(train_loader)*num_epochs\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "     \n",
    "        '''Training of the model'''\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)  \n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        '''Evaluating the model every x steps'''\n",
    "        if global_step % eval_every == 0:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                val_running_loss = 0.0\n",
    "                for val_inputs, val_labels in valid_loader:\n",
    "                    val_outputs = net(val_inputs)\n",
    "\n",
    "                    val_loss = criterion(val_outputs, val_labels.float())\n",
    "                    val_running_loss += val_loss.item()\n",
    "\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_val_loss = val_running_loss / len(valid_loader)\n",
    "\n",
    "                # ...log the running loss\n",
    "                writer.add_scalar(\n",
    "                    f'training loss {num_epochs}', average_train_loss, global_step)\n",
    "\n",
    "                # ...log the running loss\n",
    "                writer.add_scalar(\n",
    "                    f'validation loss {num_epochs}', average_val_loss, global_step)\n",
    "\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, total_step, average_train_loss, average_val_loss))\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [20/5530], Train Loss: 0.7076, Valid Loss: 0.6670\n",
      "Epoch [1/10], Step [40/5530], Train Loss: 0.6815, Valid Loss: 0.6586\n",
      "Epoch [1/10], Step [60/5530], Train Loss: 0.6585, Valid Loss: 0.6408\n",
      "Epoch [1/10], Step [80/5530], Train Loss: 0.6521, Valid Loss: 0.6268\n",
      "Epoch [1/10], Step [100/5530], Train Loss: 0.6317, Valid Loss: 0.6132\n",
      "Epoch [1/10], Step [120/5530], Train Loss: 0.6174, Valid Loss: 0.5894\n",
      "Epoch [1/10], Step [140/5530], Train Loss: 0.5952, Valid Loss: 0.5700\n",
      "Epoch [1/10], Step [160/5530], Train Loss: 0.5826, Valid Loss: 0.5528\n",
      "Epoch [1/10], Step [180/5530], Train Loss: 0.5590, Valid Loss: 0.5360\n",
      "Epoch [1/10], Step [200/5530], Train Loss: 0.5436, Valid Loss: 0.5139\n",
      "Epoch [1/10], Step [220/5530], Train Loss: 0.5218, Valid Loss: 0.5001\n",
      "Epoch [1/10], Step [240/5530], Train Loss: 0.5121, Valid Loss: 0.4927\n",
      "Epoch [1/10], Step [260/5530], Train Loss: 0.4944, Valid Loss: 0.4846\n",
      "Epoch [1/10], Step [280/5530], Train Loss: 0.4834, Valid Loss: 0.4797\n",
      "Epoch [1/10], Step [300/5530], Train Loss: 0.4817, Valid Loss: 0.4741\n",
      "Epoch [1/10], Step [320/5530], Train Loss: 0.4603, Valid Loss: 0.4735\n",
      "Epoch [1/10], Step [340/5530], Train Loss: 0.4878, Valid Loss: 0.4668\n",
      "Epoch [1/10], Step [360/5530], Train Loss: 0.4795, Valid Loss: 0.4695\n",
      "Epoch [1/10], Step [380/5530], Train Loss: 0.4789, Valid Loss: 0.4697\n",
      "Epoch [1/10], Step [400/5530], Train Loss: 0.4798, Valid Loss: 0.4691\n",
      "Epoch [1/10], Step [420/5530], Train Loss: 0.4693, Valid Loss: 0.4679\n",
      "Epoch [1/10], Step [440/5530], Train Loss: 0.4688, Valid Loss: 0.4660\n",
      "Epoch [1/10], Step [460/5530], Train Loss: 0.4733, Valid Loss: 0.4701\n",
      "Epoch [1/10], Step [480/5530], Train Loss: 0.4733, Valid Loss: 0.4651\n",
      "Epoch [1/10], Step [500/5530], Train Loss: 0.4774, Valid Loss: 0.4665\n",
      "Epoch [1/10], Step [520/5530], Train Loss: 0.4669, Valid Loss: 0.4647\n",
      "Epoch [1/10], Step [540/5530], Train Loss: 0.4587, Valid Loss: 0.4642\n",
      "Epoch [2/10], Step [560/5530], Train Loss: 0.4718, Valid Loss: 0.4623\n",
      "Epoch [2/10], Step [580/5530], Train Loss: 0.4691, Valid Loss: 0.4628\n",
      "Epoch [2/10], Step [600/5530], Train Loss: 0.4737, Valid Loss: 0.4611\n",
      "Epoch [2/10], Step [620/5530], Train Loss: 0.4735, Valid Loss: 0.4613\n",
      "Epoch [2/10], Step [640/5530], Train Loss: 0.4760, Valid Loss: 0.4646\n",
      "Epoch [2/10], Step [660/5530], Train Loss: 0.4657, Valid Loss: 0.4650\n",
      "Epoch [2/10], Step [680/5530], Train Loss: 0.4505, Valid Loss: 0.4645\n",
      "Epoch [2/10], Step [700/5530], Train Loss: 0.4615, Valid Loss: 0.4622\n",
      "Epoch [2/10], Step [720/5530], Train Loss: 0.4605, Valid Loss: 0.4629\n",
      "Epoch [2/10], Step [740/5530], Train Loss: 0.4488, Valid Loss: 0.4621\n",
      "Epoch [2/10], Step [760/5530], Train Loss: 0.4885, Valid Loss: 0.4640\n",
      "Epoch [2/10], Step [780/5530], Train Loss: 0.4513, Valid Loss: 0.4643\n",
      "Epoch [2/10], Step [800/5530], Train Loss: 0.4856, Valid Loss: 0.4593\n",
      "Epoch [2/10], Step [820/5530], Train Loss: 0.4747, Valid Loss: 0.4595\n",
      "Epoch [2/10], Step [840/5530], Train Loss: 0.4649, Valid Loss: 0.4615\n",
      "Epoch [2/10], Step [860/5530], Train Loss: 0.4919, Valid Loss: 0.4602\n",
      "Epoch [2/10], Step [880/5530], Train Loss: 0.4629, Valid Loss: 0.4603\n",
      "Epoch [2/10], Step [900/5530], Train Loss: 0.4702, Valid Loss: 0.4582\n",
      "Epoch [2/10], Step [920/5530], Train Loss: 0.4761, Valid Loss: 0.4597\n",
      "Epoch [2/10], Step [940/5530], Train Loss: 0.4742, Valid Loss: 0.4587\n",
      "Epoch [2/10], Step [960/5530], Train Loss: 0.4715, Valid Loss: 0.4583\n",
      "Epoch [2/10], Step [980/5530], Train Loss: 0.4816, Valid Loss: 0.4597\n",
      "Epoch [2/10], Step [1000/5530], Train Loss: 0.4596, Valid Loss: 0.4615\n",
      "Epoch [2/10], Step [1020/5530], Train Loss: 0.4695, Valid Loss: 0.4586\n",
      "Epoch [2/10], Step [1040/5530], Train Loss: 0.4604, Valid Loss: 0.4576\n",
      "Epoch [2/10], Step [1060/5530], Train Loss: 0.4503, Valid Loss: 0.4658\n",
      "Epoch [2/10], Step [1080/5530], Train Loss: 0.4573, Valid Loss: 0.4579\n",
      "Epoch [2/10], Step [1100/5530], Train Loss: 0.4524, Valid Loss: 0.4590\n",
      "Epoch [3/10], Step [1120/5530], Train Loss: 0.4633, Valid Loss: 0.4575\n",
      "Epoch [3/10], Step [1140/5530], Train Loss: 0.4649, Valid Loss: 0.4556\n",
      "Epoch [3/10], Step [1160/5530], Train Loss: 0.4843, Valid Loss: 0.4579\n",
      "Epoch [3/10], Step [1180/5530], Train Loss: 0.4763, Valid Loss: 0.4598\n",
      "Epoch [3/10], Step [1200/5530], Train Loss: 0.4679, Valid Loss: 0.4584\n",
      "Epoch [3/10], Step [1220/5530], Train Loss: 0.4634, Valid Loss: 0.4640\n",
      "Epoch [3/10], Step [1240/5530], Train Loss: 0.4666, Valid Loss: 0.4627\n",
      "Epoch [3/10], Step [1260/5530], Train Loss: 0.4800, Valid Loss: 0.4628\n",
      "Epoch [3/10], Step [1280/5530], Train Loss: 0.4622, Valid Loss: 0.4578\n",
      "Epoch [3/10], Step [1300/5530], Train Loss: 0.4675, Valid Loss: 0.4564\n",
      "Epoch [3/10], Step [1320/5530], Train Loss: 0.4673, Valid Loss: 0.4561\n",
      "Epoch [3/10], Step [1340/5530], Train Loss: 0.4543, Valid Loss: 0.4572\n",
      "Epoch [3/10], Step [1360/5530], Train Loss: 0.4581, Valid Loss: 0.4569\n",
      "Epoch [3/10], Step [1380/5530], Train Loss: 0.4649, Valid Loss: 0.4560\n",
      "Epoch [3/10], Step [1400/5530], Train Loss: 0.4575, Valid Loss: 0.4572\n",
      "Epoch [3/10], Step [1420/5530], Train Loss: 0.4668, Valid Loss: 0.4592\n",
      "Epoch [3/10], Step [1440/5530], Train Loss: 0.4301, Valid Loss: 0.4594\n",
      "Epoch [3/10], Step [1460/5530], Train Loss: 0.4666, Valid Loss: 0.4656\n",
      "Epoch [3/10], Step [1480/5530], Train Loss: 0.4262, Valid Loss: 0.4571\n",
      "Epoch [3/10], Step [1500/5530], Train Loss: 0.4761, Valid Loss: 0.4615\n",
      "Epoch [3/10], Step [1520/5530], Train Loss: 0.4661, Valid Loss: 0.4578\n",
      "Epoch [3/10], Step [1540/5530], Train Loss: 0.4486, Valid Loss: 0.4575\n",
      "Epoch [3/10], Step [1560/5530], Train Loss: 0.4792, Valid Loss: 0.4582\n",
      "Epoch [3/10], Step [1580/5530], Train Loss: 0.4516, Valid Loss: 0.4593\n",
      "Epoch [3/10], Step [1600/5530], Train Loss: 0.4772, Valid Loss: 0.4613\n",
      "Epoch [3/10], Step [1620/5530], Train Loss: 0.4397, Valid Loss: 0.4583\n",
      "Epoch [3/10], Step [1640/5530], Train Loss: 0.4477, Valid Loss: 0.4590\n",
      "Epoch [4/10], Step [1660/5530], Train Loss: 0.4505, Valid Loss: 0.4601\n",
      "Epoch [4/10], Step [1680/5530], Train Loss: 0.4580, Valid Loss: 0.4625\n",
      "Epoch [4/10], Step [1700/5530], Train Loss: 0.4670, Valid Loss: 0.4595\n",
      "Epoch [4/10], Step [1720/5530], Train Loss: 0.4693, Valid Loss: 0.4587\n",
      "Epoch [4/10], Step [1740/5530], Train Loss: 0.4729, Valid Loss: 0.4615\n",
      "Epoch [4/10], Step [1760/5530], Train Loss: 0.4692, Valid Loss: 0.4614\n",
      "Epoch [4/10], Step [1780/5530], Train Loss: 0.4456, Valid Loss: 0.4583\n",
      "Epoch [4/10], Step [1800/5530], Train Loss: 0.4569, Valid Loss: 0.4589\n",
      "Epoch [4/10], Step [1820/5530], Train Loss: 0.4445, Valid Loss: 0.4572\n",
      "Epoch [4/10], Step [1840/5530], Train Loss: 0.4792, Valid Loss: 0.4608\n",
      "Epoch [4/10], Step [1860/5530], Train Loss: 0.4690, Valid Loss: 0.4644\n",
      "Epoch [4/10], Step [1880/5530], Train Loss: 0.4471, Valid Loss: 0.4583\n",
      "Epoch [4/10], Step [1900/5530], Train Loss: 0.4202, Valid Loss: 0.4591\n",
      "Epoch [4/10], Step [1920/5530], Train Loss: 0.4511, Valid Loss: 0.4624\n",
      "Epoch [4/10], Step [1940/5530], Train Loss: 0.4852, Valid Loss: 0.4553\n",
      "Epoch [4/10], Step [1960/5530], Train Loss: 0.4732, Valid Loss: 0.4569\n",
      "Epoch [4/10], Step [1980/5530], Train Loss: 0.4600, Valid Loss: 0.4592\n",
      "Epoch [4/10], Step [2000/5530], Train Loss: 0.4653, Valid Loss: 0.4579\n",
      "Epoch [4/10], Step [2020/5530], Train Loss: 0.4528, Valid Loss: 0.4628\n",
      "Epoch [4/10], Step [2040/5530], Train Loss: 0.4567, Valid Loss: 0.4575\n",
      "Epoch [4/10], Step [2060/5530], Train Loss: 0.4517, Valid Loss: 0.4589\n",
      "Epoch [4/10], Step [2080/5530], Train Loss: 0.4337, Valid Loss: 0.4563\n",
      "Epoch [4/10], Step [2100/5530], Train Loss: 0.4576, Valid Loss: 0.4592\n",
      "Epoch [4/10], Step [2120/5530], Train Loss: 0.4709, Valid Loss: 0.4561\n",
      "Epoch [4/10], Step [2140/5530], Train Loss: 0.4590, Valid Loss: 0.4613\n",
      "Epoch [4/10], Step [2160/5530], Train Loss: 0.4655, Valid Loss: 0.4575\n",
      "Epoch [4/10], Step [2180/5530], Train Loss: 0.4624, Valid Loss: 0.4569\n",
      "Epoch [4/10], Step [2200/5530], Train Loss: 0.4642, Valid Loss: 0.4550\n",
      "Epoch [5/10], Step [2220/5530], Train Loss: 0.4672, Valid Loss: 0.4568\n",
      "Epoch [5/10], Step [2240/5530], Train Loss: 0.4640, Valid Loss: 0.4597\n",
      "Epoch [5/10], Step [2260/5530], Train Loss: 0.4533, Valid Loss: 0.4574\n",
      "Epoch [5/10], Step [2280/5530], Train Loss: 0.4682, Valid Loss: 0.4597\n",
      "Epoch [5/10], Step [2300/5530], Train Loss: 0.4663, Valid Loss: 0.4588\n",
      "Epoch [5/10], Step [2320/5530], Train Loss: 0.4510, Valid Loss: 0.4572\n",
      "Epoch [5/10], Step [2340/5530], Train Loss: 0.4485, Valid Loss: 0.4606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [2360/5530], Train Loss: 0.4765, Valid Loss: 0.4540\n",
      "Epoch [5/10], Step [2380/5530], Train Loss: 0.4584, Valid Loss: 0.4572\n",
      "Epoch [5/10], Step [2400/5530], Train Loss: 0.4885, Valid Loss: 0.4537\n",
      "Epoch [5/10], Step [2420/5530], Train Loss: 0.4338, Valid Loss: 0.4587\n",
      "Epoch [5/10], Step [2440/5530], Train Loss: 0.4541, Valid Loss: 0.4598\n",
      "Epoch [5/10], Step [2460/5530], Train Loss: 0.4517, Valid Loss: 0.4569\n",
      "Epoch [5/10], Step [2480/5530], Train Loss: 0.4405, Valid Loss: 0.4593\n",
      "Epoch [5/10], Step [2500/5530], Train Loss: 0.4624, Valid Loss: 0.4583\n",
      "Epoch [5/10], Step [2520/5530], Train Loss: 0.4550, Valid Loss: 0.4599\n",
      "Epoch [5/10], Step [2540/5530], Train Loss: 0.4559, Valid Loss: 0.4570\n",
      "Epoch [5/10], Step [2560/5530], Train Loss: 0.4580, Valid Loss: 0.4574\n",
      "Epoch [5/10], Step [2580/5530], Train Loss: 0.4622, Valid Loss: 0.4609\n",
      "Epoch [5/10], Step [2600/5530], Train Loss: 0.4434, Valid Loss: 0.4607\n",
      "Epoch [5/10], Step [2620/5530], Train Loss: 0.4399, Valid Loss: 0.4553\n",
      "Epoch [5/10], Step [2640/5530], Train Loss: 0.4309, Valid Loss: 0.4555\n",
      "Epoch [5/10], Step [2660/5530], Train Loss: 0.4551, Valid Loss: 0.4578\n",
      "Epoch [5/10], Step [2680/5530], Train Loss: 0.4574, Valid Loss: 0.4537\n",
      "Epoch [5/10], Step [2700/5530], Train Loss: 0.4515, Valid Loss: 0.4621\n",
      "Epoch [5/10], Step [2720/5530], Train Loss: 0.4568, Valid Loss: 0.4533\n",
      "Epoch [5/10], Step [2740/5530], Train Loss: 0.4653, Valid Loss: 0.4567\n",
      "Epoch [5/10], Step [2760/5530], Train Loss: 0.4331, Valid Loss: 0.4544\n",
      "Epoch [6/10], Step [2780/5530], Train Loss: 0.4283, Valid Loss: 0.4542\n",
      "Epoch [6/10], Step [2800/5530], Train Loss: 0.4531, Valid Loss: 0.4543\n",
      "Epoch [6/10], Step [2820/5530], Train Loss: 0.4525, Valid Loss: 0.4559\n",
      "Epoch [6/10], Step [2840/5530], Train Loss: 0.4561, Valid Loss: 0.4608\n",
      "Epoch [6/10], Step [2860/5530], Train Loss: 0.4477, Valid Loss: 0.4586\n",
      "Epoch [6/10], Step [2880/5530], Train Loss: 0.4574, Valid Loss: 0.4567\n",
      "Epoch [6/10], Step [2900/5530], Train Loss: 0.4376, Valid Loss: 0.4554\n",
      "Epoch [6/10], Step [2920/5530], Train Loss: 0.4476, Valid Loss: 0.4591\n",
      "Epoch [6/10], Step [2940/5530], Train Loss: 0.4725, Valid Loss: 0.4556\n",
      "Epoch [6/10], Step [2960/5530], Train Loss: 0.4415, Valid Loss: 0.4567\n",
      "Epoch [6/10], Step [2980/5530], Train Loss: 0.4435, Valid Loss: 0.4587\n",
      "Epoch [6/10], Step [3000/5530], Train Loss: 0.4438, Valid Loss: 0.4606\n",
      "Epoch [6/10], Step [3020/5530], Train Loss: 0.4504, Valid Loss: 0.4534\n",
      "Epoch [6/10], Step [3040/5530], Train Loss: 0.4577, Valid Loss: 0.4523\n",
      "Epoch [6/10], Step [3060/5530], Train Loss: 0.4434, Valid Loss: 0.4543\n",
      "Epoch [6/10], Step [3080/5530], Train Loss: 0.4383, Valid Loss: 0.4537\n",
      "Epoch [6/10], Step [3100/5530], Train Loss: 0.4651, Valid Loss: 0.4540\n",
      "Epoch [6/10], Step [3120/5530], Train Loss: 0.4617, Valid Loss: 0.4556\n",
      "Epoch [6/10], Step [3140/5530], Train Loss: 0.4626, Valid Loss: 0.4538\n",
      "Epoch [6/10], Step [3160/5530], Train Loss: 0.4576, Valid Loss: 0.4561\n",
      "Epoch [6/10], Step [3180/5530], Train Loss: 0.4634, Valid Loss: 0.4532\n",
      "Epoch [6/10], Step [3200/5530], Train Loss: 0.4415, Valid Loss: 0.4527\n",
      "Epoch [6/10], Step [3220/5530], Train Loss: 0.4625, Valid Loss: 0.4559\n",
      "Epoch [6/10], Step [3240/5530], Train Loss: 0.4686, Valid Loss: 0.4532\n",
      "Epoch [6/10], Step [3260/5530], Train Loss: 0.4595, Valid Loss: 0.4532\n",
      "Epoch [6/10], Step [3280/5530], Train Loss: 0.4481, Valid Loss: 0.4547\n",
      "Epoch [6/10], Step [3300/5530], Train Loss: 0.4592, Valid Loss: 0.4546\n",
      "Epoch [7/10], Step [3320/5530], Train Loss: 0.4567, Valid Loss: 0.4568\n",
      "Epoch [7/10], Step [3340/5530], Train Loss: 0.4551, Valid Loss: 0.4531\n",
      "Epoch [7/10], Step [3360/5530], Train Loss: 0.4396, Valid Loss: 0.4579\n",
      "Epoch [7/10], Step [3380/5530], Train Loss: 0.4675, Valid Loss: 0.4532\n",
      "Epoch [7/10], Step [3400/5530], Train Loss: 0.4771, Valid Loss: 0.4541\n",
      "Epoch [7/10], Step [3420/5530], Train Loss: 0.4619, Valid Loss: 0.4591\n",
      "Epoch [7/10], Step [3440/5530], Train Loss: 0.4517, Valid Loss: 0.4559\n",
      "Epoch [7/10], Step [3460/5530], Train Loss: 0.4403, Valid Loss: 0.4527\n",
      "Epoch [7/10], Step [3480/5530], Train Loss: 0.4355, Valid Loss: 0.4531\n",
      "Epoch [7/10], Step [3500/5530], Train Loss: 0.4677, Valid Loss: 0.4612\n",
      "Epoch [7/10], Step [3520/5530], Train Loss: 0.4495, Valid Loss: 0.4568\n",
      "Epoch [7/10], Step [3540/5530], Train Loss: 0.4540, Valid Loss: 0.4579\n",
      "Epoch [7/10], Step [3560/5530], Train Loss: 0.4739, Valid Loss: 0.4551\n",
      "Epoch [7/10], Step [3580/5530], Train Loss: 0.4373, Valid Loss: 0.4568\n",
      "Epoch [7/10], Step [3600/5530], Train Loss: 0.4559, Valid Loss: 0.4563\n",
      "Epoch [7/10], Step [3620/5530], Train Loss: 0.4395, Valid Loss: 0.4527\n",
      "Epoch [7/10], Step [3640/5530], Train Loss: 0.4489, Valid Loss: 0.4622\n",
      "Epoch [7/10], Step [3660/5530], Train Loss: 0.4532, Valid Loss: 0.4586\n",
      "Epoch [7/10], Step [3680/5530], Train Loss: 0.4501, Valid Loss: 0.4615\n",
      "Epoch [7/10], Step [3700/5530], Train Loss: 0.4576, Valid Loss: 0.4626\n",
      "Epoch [7/10], Step [3720/5530], Train Loss: 0.4549, Valid Loss: 0.4573\n",
      "Epoch [7/10], Step [3740/5530], Train Loss: 0.4513, Valid Loss: 0.4592\n",
      "Epoch [7/10], Step [3760/5530], Train Loss: 0.4631, Valid Loss: 0.4548\n",
      "Epoch [7/10], Step [3780/5530], Train Loss: 0.4439, Valid Loss: 0.4561\n",
      "Epoch [7/10], Step [3800/5530], Train Loss: 0.4575, Valid Loss: 0.4556\n",
      "Epoch [7/10], Step [3820/5530], Train Loss: 0.4392, Valid Loss: 0.4548\n",
      "Epoch [7/10], Step [3840/5530], Train Loss: 0.4520, Valid Loss: 0.4560\n",
      "Epoch [7/10], Step [3860/5530], Train Loss: 0.4324, Valid Loss: 0.4561\n",
      "Epoch [8/10], Step [3880/5530], Train Loss: 0.4666, Valid Loss: 0.4557\n",
      "Epoch [8/10], Step [3900/5530], Train Loss: 0.4486, Valid Loss: 0.4538\n",
      "Epoch [8/10], Step [3920/5530], Train Loss: 0.4397, Valid Loss: 0.4533\n",
      "Epoch [8/10], Step [3940/5530], Train Loss: 0.4411, Valid Loss: 0.4546\n",
      "Epoch [8/10], Step [3960/5530], Train Loss: 0.4487, Valid Loss: 0.4559\n",
      "Epoch [8/10], Step [3980/5530], Train Loss: 0.4347, Valid Loss: 0.4556\n",
      "Epoch [8/10], Step [4000/5530], Train Loss: 0.4485, Valid Loss: 0.4560\n",
      "Epoch [8/10], Step [4020/5530], Train Loss: 0.4389, Valid Loss: 0.4577\n",
      "Epoch [8/10], Step [4040/5530], Train Loss: 0.4439, Valid Loss: 0.4571\n",
      "Epoch [8/10], Step [4060/5530], Train Loss: 0.4658, Valid Loss: 0.4513\n",
      "Epoch [8/10], Step [4080/5530], Train Loss: 0.4444, Valid Loss: 0.4563\n",
      "Epoch [8/10], Step [4100/5530], Train Loss: 0.4497, Valid Loss: 0.4562\n",
      "Epoch [8/10], Step [4120/5530], Train Loss: 0.4413, Valid Loss: 0.4574\n",
      "Epoch [8/10], Step [4140/5530], Train Loss: 0.4455, Valid Loss: 0.4542\n",
      "Epoch [8/10], Step [4160/5530], Train Loss: 0.4179, Valid Loss: 0.4533\n",
      "Epoch [8/10], Step [4180/5530], Train Loss: 0.4249, Valid Loss: 0.4531\n",
      "Epoch [8/10], Step [4200/5530], Train Loss: 0.4640, Valid Loss: 0.4555\n",
      "Epoch [8/10], Step [4220/5530], Train Loss: 0.4445, Valid Loss: 0.4547\n",
      "Epoch [8/10], Step [4240/5530], Train Loss: 0.4509, Valid Loss: 0.4535\n",
      "Epoch [8/10], Step [4260/5530], Train Loss: 0.4553, Valid Loss: 0.4549\n",
      "Epoch [8/10], Step [4280/5530], Train Loss: 0.4465, Valid Loss: 0.4576\n",
      "Epoch [8/10], Step [4300/5530], Train Loss: 0.4480, Valid Loss: 0.4543\n",
      "Epoch [8/10], Step [4320/5530], Train Loss: 0.4458, Valid Loss: 0.4562\n",
      "Epoch [8/10], Step [4340/5530], Train Loss: 0.4443, Valid Loss: 0.4571\n",
      "Epoch [8/10], Step [4360/5530], Train Loss: 0.4801, Valid Loss: 0.4582\n",
      "Epoch [8/10], Step [4380/5530], Train Loss: 0.4492, Valid Loss: 0.4553\n",
      "Epoch [8/10], Step [4400/5530], Train Loss: 0.4419, Valid Loss: 0.4542\n",
      "Epoch [8/10], Step [4420/5530], Train Loss: 0.4779, Valid Loss: 0.4571\n",
      "Epoch [9/10], Step [4440/5530], Train Loss: 0.4370, Valid Loss: 0.4529\n",
      "Epoch [9/10], Step [4460/5530], Train Loss: 0.4549, Valid Loss: 0.4529\n",
      "Epoch [9/10], Step [4480/5530], Train Loss: 0.4610, Valid Loss: 0.4528\n",
      "Epoch [9/10], Step [4500/5530], Train Loss: 0.4558, Valid Loss: 0.4528\n",
      "Epoch [9/10], Step [4520/5530], Train Loss: 0.4475, Valid Loss: 0.4535\n",
      "Epoch [9/10], Step [4540/5530], Train Loss: 0.4517, Valid Loss: 0.4523\n",
      "Epoch [9/10], Step [4560/5530], Train Loss: 0.4314, Valid Loss: 0.4529\n",
      "Epoch [9/10], Step [4580/5530], Train Loss: 0.4387, Valid Loss: 0.4545\n",
      "Epoch [9/10], Step [4600/5530], Train Loss: 0.4659, Valid Loss: 0.4538\n",
      "Epoch [9/10], Step [4620/5530], Train Loss: 0.4476, Valid Loss: 0.4527\n",
      "Epoch [9/10], Step [4640/5530], Train Loss: 0.4358, Valid Loss: 0.4549\n",
      "Epoch [9/10], Step [4660/5530], Train Loss: 0.4404, Valid Loss: 0.4522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [4680/5530], Train Loss: 0.4482, Valid Loss: 0.4538\n",
      "Epoch [9/10], Step [4700/5530], Train Loss: 0.4440, Valid Loss: 0.4564\n",
      "Epoch [9/10], Step [4720/5530], Train Loss: 0.4241, Valid Loss: 0.4539\n",
      "Epoch [9/10], Step [4740/5530], Train Loss: 0.4515, Valid Loss: 0.4552\n",
      "Epoch [9/10], Step [4760/5530], Train Loss: 0.4646, Valid Loss: 0.4534\n",
      "Epoch [9/10], Step [4780/5530], Train Loss: 0.4640, Valid Loss: 0.4538\n",
      "Epoch [9/10], Step [4800/5530], Train Loss: 0.4378, Valid Loss: 0.4529\n",
      "Epoch [9/10], Step [4820/5530], Train Loss: 0.4541, Valid Loss: 0.4636\n",
      "Epoch [9/10], Step [4840/5530], Train Loss: 0.4473, Valid Loss: 0.4561\n",
      "Epoch [9/10], Step [4860/5530], Train Loss: 0.4455, Valid Loss: 0.4540\n",
      "Epoch [9/10], Step [4880/5530], Train Loss: 0.4390, Valid Loss: 0.4534\n",
      "Epoch [9/10], Step [4900/5530], Train Loss: 0.4612, Valid Loss: 0.4516\n",
      "Epoch [9/10], Step [4920/5530], Train Loss: 0.4470, Valid Loss: 0.4501\n",
      "Epoch [9/10], Step [4940/5530], Train Loss: 0.4412, Valid Loss: 0.4511\n",
      "Epoch [9/10], Step [4960/5530], Train Loss: 0.4446, Valid Loss: 0.4492\n",
      "Epoch [10/10], Step [4980/5530], Train Loss: 0.4504, Valid Loss: 0.4531\n",
      "Epoch [10/10], Step [5000/5530], Train Loss: 0.4346, Valid Loss: 0.4531\n",
      "Epoch [10/10], Step [5020/5530], Train Loss: 0.4430, Valid Loss: 0.4508\n",
      "Epoch [10/10], Step [5040/5530], Train Loss: 0.4330, Valid Loss: 0.4541\n",
      "Epoch [10/10], Step [5060/5530], Train Loss: 0.4190, Valid Loss: 0.4519\n",
      "Epoch [10/10], Step [5080/5530], Train Loss: 0.4258, Valid Loss: 0.4550\n",
      "Epoch [10/10], Step [5100/5530], Train Loss: 0.4566, Valid Loss: 0.4535\n",
      "Epoch [10/10], Step [5120/5530], Train Loss: 0.4652, Valid Loss: 0.4515\n",
      "Epoch [10/10], Step [5140/5530], Train Loss: 0.4249, Valid Loss: 0.4525\n",
      "Epoch [10/10], Step [5160/5530], Train Loss: 0.4368, Valid Loss: 0.4525\n",
      "Epoch [10/10], Step [5180/5530], Train Loss: 0.4432, Valid Loss: 0.4506\n",
      "Epoch [10/10], Step [5200/5530], Train Loss: 0.4339, Valid Loss: 0.4534\n",
      "Epoch [10/10], Step [5220/5530], Train Loss: 0.4440, Valid Loss: 0.4546\n",
      "Epoch [10/10], Step [5240/5530], Train Loss: 0.4609, Valid Loss: 0.4564\n",
      "Epoch [10/10], Step [5260/5530], Train Loss: 0.4533, Valid Loss: 0.4536\n",
      "Epoch [10/10], Step [5280/5530], Train Loss: 0.4465, Valid Loss: 0.4527\n",
      "Epoch [10/10], Step [5300/5530], Train Loss: 0.4487, Valid Loss: 0.4539\n",
      "Epoch [10/10], Step [5320/5530], Train Loss: 0.4522, Valid Loss: 0.4598\n",
      "Epoch [10/10], Step [5340/5530], Train Loss: 0.4642, Valid Loss: 0.4552\n",
      "Epoch [10/10], Step [5360/5530], Train Loss: 0.4670, Valid Loss: 0.4508\n",
      "Epoch [10/10], Step [5380/5530], Train Loss: 0.4603, Valid Loss: 0.4505\n",
      "Epoch [10/10], Step [5400/5530], Train Loss: 0.4430, Valid Loss: 0.4520\n",
      "Epoch [10/10], Step [5420/5530], Train Loss: 0.4316, Valid Loss: 0.4530\n",
      "Epoch [10/10], Step [5440/5530], Train Loss: 0.4544, Valid Loss: 0.4535\n",
      "Epoch [10/10], Step [5460/5530], Train Loss: 0.4524, Valid Loss: 0.4534\n",
      "Epoch [10/10], Step [5480/5530], Train Loss: 0.4667, Valid Loss: 0.4563\n",
      "Epoch [10/10], Step [5500/5530], Train Loss: 0.4474, Valid Loss: 0.4555\n",
      "Epoch [10/10], Step [5520/5530], Train Loss: 0.4479, Valid Loss: 0.4519\n",
      "Finished Training\n",
      "Epoch [1/10], Step [20/5530], Train Loss: 0.7319, Valid Loss: 0.6726\n",
      "Epoch [1/10], Step [40/5530], Train Loss: 0.7165, Valid Loss: 0.6690\n",
      "Epoch [1/10], Step [60/5530], Train Loss: 0.7120, Valid Loss: 0.6683\n",
      "Epoch [1/10], Step [80/5530], Train Loss: 0.6966, Valid Loss: 0.6721\n",
      "Epoch [1/10], Step [100/5530], Train Loss: 0.6999, Valid Loss: 0.6636\n",
      "Epoch [1/10], Step [120/5530], Train Loss: 0.6870, Valid Loss: 0.6659\n",
      "Epoch [1/10], Step [140/5530], Train Loss: 0.6860, Valid Loss: 0.6493\n",
      "Epoch [1/10], Step [160/5530], Train Loss: 0.6752, Valid Loss: 0.6449\n",
      "Epoch [1/10], Step [180/5530], Train Loss: 0.6688, Valid Loss: 0.6427\n",
      "Epoch [1/10], Step [200/5530], Train Loss: 0.6734, Valid Loss: 0.6412\n",
      "Epoch [1/10], Step [220/5530], Train Loss: 0.6649, Valid Loss: 0.6374\n",
      "Epoch [1/10], Step [240/5530], Train Loss: 0.6465, Valid Loss: 0.6355\n",
      "Epoch [1/10], Step [260/5530], Train Loss: 0.6506, Valid Loss: 0.6310\n",
      "Epoch [1/10], Step [280/5530], Train Loss: 0.6460, Valid Loss: 0.6288\n",
      "Epoch [1/10], Step [300/5530], Train Loss: 0.6390, Valid Loss: 0.6182\n",
      "Epoch [1/10], Step [320/5530], Train Loss: 0.6345, Valid Loss: 0.6161\n",
      "Epoch [1/10], Step [340/5530], Train Loss: 0.6281, Valid Loss: 0.6083\n",
      "Epoch [1/10], Step [360/5530], Train Loss: 0.6301, Valid Loss: 0.5985\n",
      "Epoch [1/10], Step [380/5530], Train Loss: 0.6129, Valid Loss: 0.5932\n",
      "Epoch [1/10], Step [400/5530], Train Loss: 0.6144, Valid Loss: 0.5868\n",
      "Epoch [1/10], Step [420/5530], Train Loss: 0.6046, Valid Loss: 0.5852\n",
      "Epoch [1/10], Step [440/5530], Train Loss: 0.5954, Valid Loss: 0.5764\n",
      "Epoch [1/10], Step [460/5530], Train Loss: 0.5923, Valid Loss: 0.5699\n",
      "Epoch [1/10], Step [480/5530], Train Loss: 0.5808, Valid Loss: 0.5629\n",
      "Epoch [1/10], Step [500/5530], Train Loss: 0.5876, Valid Loss: 0.5554\n",
      "Epoch [1/10], Step [520/5530], Train Loss: 0.5720, Valid Loss: 0.5467\n",
      "Epoch [1/10], Step [540/5530], Train Loss: 0.5609, Valid Loss: 0.5444\n",
      "Epoch [2/10], Step [560/5530], Train Loss: 0.5671, Valid Loss: 0.5357\n",
      "Epoch [2/10], Step [580/5530], Train Loss: 0.5511, Valid Loss: 0.5299\n",
      "Epoch [2/10], Step [600/5530], Train Loss: 0.5379, Valid Loss: 0.5283\n",
      "Epoch [2/10], Step [620/5530], Train Loss: 0.5583, Valid Loss: 0.5268\n",
      "Epoch [2/10], Step [640/5530], Train Loss: 0.5326, Valid Loss: 0.5150\n",
      "Epoch [2/10], Step [660/5530], Train Loss: 0.5384, Valid Loss: 0.5155\n",
      "Epoch [2/10], Step [680/5530], Train Loss: 0.5300, Valid Loss: 0.5073\n",
      "Epoch [2/10], Step [700/5530], Train Loss: 0.5310, Valid Loss: 0.5059\n",
      "Epoch [2/10], Step [720/5530], Train Loss: 0.5189, Valid Loss: 0.5007\n",
      "Epoch [2/10], Step [740/5530], Train Loss: 0.5180, Valid Loss: 0.5002\n",
      "Epoch [2/10], Step [760/5530], Train Loss: 0.5181, Valid Loss: 0.4928\n",
      "Epoch [2/10], Step [780/5530], Train Loss: 0.5087, Valid Loss: 0.4910\n",
      "Epoch [2/10], Step [800/5530], Train Loss: 0.4967, Valid Loss: 0.4866\n",
      "Epoch [2/10], Step [820/5530], Train Loss: 0.4891, Valid Loss: 0.4846\n",
      "Epoch [2/10], Step [840/5530], Train Loss: 0.5169, Valid Loss: 0.4846\n",
      "Epoch [2/10], Step [860/5530], Train Loss: 0.5011, Valid Loss: 0.4829\n",
      "Epoch [2/10], Step [880/5530], Train Loss: 0.4907, Valid Loss: 0.4788\n",
      "Epoch [2/10], Step [900/5530], Train Loss: 0.4895, Valid Loss: 0.4778\n",
      "Epoch [2/10], Step [920/5530], Train Loss: 0.4884, Valid Loss: 0.4783\n",
      "Epoch [2/10], Step [940/5530], Train Loss: 0.4697, Valid Loss: 0.4732\n",
      "Epoch [2/10], Step [960/5530], Train Loss: 0.4918, Valid Loss: 0.4743\n",
      "Epoch [2/10], Step [980/5530], Train Loss: 0.4973, Valid Loss: 0.4743\n",
      "Epoch [2/10], Step [1000/5530], Train Loss: 0.4913, Valid Loss: 0.4724\n",
      "Epoch [2/10], Step [1020/5530], Train Loss: 0.5074, Valid Loss: 0.4724\n",
      "Epoch [2/10], Step [1040/5530], Train Loss: 0.4937, Valid Loss: 0.4690\n",
      "Epoch [2/10], Step [1060/5530], Train Loss: 0.4778, Valid Loss: 0.4718\n",
      "Epoch [2/10], Step [1080/5530], Train Loss: 0.4844, Valid Loss: 0.4719\n",
      "Epoch [2/10], Step [1100/5530], Train Loss: 0.4673, Valid Loss: 0.4705\n",
      "Epoch [3/10], Step [1120/5530], Train Loss: 0.4781, Valid Loss: 0.4688\n",
      "Epoch [3/10], Step [1140/5530], Train Loss: 0.4914, Valid Loss: 0.4708\n",
      "Epoch [3/10], Step [1160/5530], Train Loss: 0.4896, Valid Loss: 0.4683\n",
      "Epoch [3/10], Step [1180/5530], Train Loss: 0.4843, Valid Loss: 0.4706\n",
      "Epoch [3/10], Step [1200/5530], Train Loss: 0.4808, Valid Loss: 0.4695\n",
      "Epoch [3/10], Step [1220/5530], Train Loss: 0.4723, Valid Loss: 0.4690\n",
      "Epoch [3/10], Step [1240/5530], Train Loss: 0.4772, Valid Loss: 0.4667\n",
      "Epoch [3/10], Step [1260/5530], Train Loss: 0.4820, Valid Loss: 0.4674\n",
      "Epoch [3/10], Step [1280/5530], Train Loss: 0.4657, Valid Loss: 0.4689\n",
      "Epoch [3/10], Step [1300/5530], Train Loss: 0.4994, Valid Loss: 0.4684\n",
      "Epoch [3/10], Step [1320/5530], Train Loss: 0.4776, Valid Loss: 0.4693\n",
      "Epoch [3/10], Step [1340/5530], Train Loss: 0.4499, Valid Loss: 0.4684\n",
      "Epoch [3/10], Step [1360/5530], Train Loss: 0.4683, Valid Loss: 0.4662\n",
      "Epoch [3/10], Step [1380/5530], Train Loss: 0.4800, Valid Loss: 0.4652\n",
      "Epoch [3/10], Step [1400/5530], Train Loss: 0.4656, Valid Loss: 0.4669\n",
      "Epoch [3/10], Step [1420/5530], Train Loss: 0.4697, Valid Loss: 0.4650\n",
      "Epoch [3/10], Step [1440/5530], Train Loss: 0.4796, Valid Loss: 0.4654\n",
      "Epoch [3/10], Step [1460/5530], Train Loss: 0.4703, Valid Loss: 0.4680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [1480/5530], Train Loss: 0.4791, Valid Loss: 0.4661\n",
      "Epoch [3/10], Step [1500/5530], Train Loss: 0.4776, Valid Loss: 0.4646\n",
      "Epoch [3/10], Step [1520/5530], Train Loss: 0.4655, Valid Loss: 0.4652\n",
      "Epoch [3/10], Step [1540/5530], Train Loss: 0.4865, Valid Loss: 0.4673\n",
      "Epoch [3/10], Step [1560/5530], Train Loss: 0.4635, Valid Loss: 0.4657\n",
      "Epoch [3/10], Step [1580/5530], Train Loss: 0.4959, Valid Loss: 0.4671\n",
      "Epoch [3/10], Step [1600/5530], Train Loss: 0.4692, Valid Loss: 0.4661\n",
      "Epoch [3/10], Step [1620/5530], Train Loss: 0.4871, Valid Loss: 0.4683\n",
      "Epoch [3/10], Step [1640/5530], Train Loss: 0.4952, Valid Loss: 0.4663\n",
      "Epoch [4/10], Step [1660/5530], Train Loss: 0.4636, Valid Loss: 0.4643\n",
      "Epoch [4/10], Step [1680/5530], Train Loss: 0.4665, Valid Loss: 0.4637\n",
      "Epoch [4/10], Step [1700/5530], Train Loss: 0.4753, Valid Loss: 0.4647\n",
      "Epoch [4/10], Step [1720/5530], Train Loss: 0.4614, Valid Loss: 0.4631\n",
      "Epoch [4/10], Step [1740/5530], Train Loss: 0.4613, Valid Loss: 0.4622\n",
      "Epoch [4/10], Step [1760/5530], Train Loss: 0.4529, Valid Loss: 0.4668\n",
      "Epoch [4/10], Step [1780/5530], Train Loss: 0.4649, Valid Loss: 0.4645\n",
      "Epoch [4/10], Step [1800/5530], Train Loss: 0.4589, Valid Loss: 0.4633\n",
      "Epoch [4/10], Step [1820/5530], Train Loss: 0.4954, Valid Loss: 0.4619\n",
      "Epoch [4/10], Step [1840/5530], Train Loss: 0.4836, Valid Loss: 0.4630\n",
      "Epoch [4/10], Step [1860/5530], Train Loss: 0.4467, Valid Loss: 0.4630\n",
      "Epoch [4/10], Step [1880/5530], Train Loss: 0.4627, Valid Loss: 0.4626\n",
      "Epoch [4/10], Step [1900/5530], Train Loss: 0.4798, Valid Loss: 0.4621\n",
      "Epoch [4/10], Step [1920/5530], Train Loss: 0.4639, Valid Loss: 0.4622\n",
      "Epoch [4/10], Step [1940/5530], Train Loss: 0.4756, Valid Loss: 0.4616\n",
      "Epoch [4/10], Step [1960/5530], Train Loss: 0.4634, Valid Loss: 0.4615\n",
      "Epoch [4/10], Step [1980/5530], Train Loss: 0.4636, Valid Loss: 0.4614\n",
      "Epoch [4/10], Step [2000/5530], Train Loss: 0.4669, Valid Loss: 0.4625\n",
      "Epoch [4/10], Step [2020/5530], Train Loss: 0.4561, Valid Loss: 0.4636\n",
      "Epoch [4/10], Step [2040/5530], Train Loss: 0.4719, Valid Loss: 0.4637\n",
      "Epoch [4/10], Step [2060/5530], Train Loss: 0.4733, Valid Loss: 0.4616\n",
      "Epoch [4/10], Step [2080/5530], Train Loss: 0.4879, Valid Loss: 0.4609\n",
      "Epoch [4/10], Step [2100/5530], Train Loss: 0.4836, Valid Loss: 0.4621\n",
      "Epoch [4/10], Step [2120/5530], Train Loss: 0.4530, Valid Loss: 0.4605\n",
      "Epoch [4/10], Step [2140/5530], Train Loss: 0.4851, Valid Loss: 0.4617\n",
      "Epoch [4/10], Step [2160/5530], Train Loss: 0.4599, Valid Loss: 0.4608\n",
      "Epoch [4/10], Step [2180/5530], Train Loss: 0.4535, Valid Loss: 0.4602\n",
      "Epoch [4/10], Step [2200/5530], Train Loss: 0.4994, Valid Loss: 0.4613\n",
      "Epoch [5/10], Step [2220/5530], Train Loss: 0.4703, Valid Loss: 0.4618\n",
      "Epoch [5/10], Step [2240/5530], Train Loss: 0.4584, Valid Loss: 0.4607\n",
      "Epoch [5/10], Step [2260/5530], Train Loss: 0.4619, Valid Loss: 0.4597\n",
      "Epoch [5/10], Step [2280/5530], Train Loss: 0.4685, Valid Loss: 0.4616\n",
      "Epoch [5/10], Step [2300/5530], Train Loss: 0.4662, Valid Loss: 0.4596\n",
      "Epoch [5/10], Step [2320/5530], Train Loss: 0.4764, Valid Loss: 0.4598\n",
      "Epoch [5/10], Step [2340/5530], Train Loss: 0.4581, Valid Loss: 0.4603\n",
      "Epoch [5/10], Step [2360/5530], Train Loss: 0.4664, Valid Loss: 0.4611\n",
      "Epoch [5/10], Step [2380/5530], Train Loss: 0.4591, Valid Loss: 0.4615\n",
      "Epoch [5/10], Step [2400/5530], Train Loss: 0.4704, Valid Loss: 0.4601\n",
      "Epoch [5/10], Step [2420/5530], Train Loss: 0.4696, Valid Loss: 0.4605\n",
      "Epoch [5/10], Step [2440/5530], Train Loss: 0.4626, Valid Loss: 0.4608\n",
      "Epoch [5/10], Step [2460/5530], Train Loss: 0.4682, Valid Loss: 0.4603\n",
      "Epoch [5/10], Step [2480/5530], Train Loss: 0.4705, Valid Loss: 0.4604\n",
      "Epoch [5/10], Step [2500/5530], Train Loss: 0.4509, Valid Loss: 0.4602\n",
      "Epoch [5/10], Step [2520/5530], Train Loss: 0.4648, Valid Loss: 0.4593\n",
      "Epoch [5/10], Step [2540/5530], Train Loss: 0.4640, Valid Loss: 0.4582\n",
      "Epoch [5/10], Step [2560/5530], Train Loss: 0.4909, Valid Loss: 0.4604\n",
      "Epoch [5/10], Step [2580/5530], Train Loss: 0.4510, Valid Loss: 0.4598\n",
      "Epoch [5/10], Step [2600/5530], Train Loss: 0.4763, Valid Loss: 0.4581\n",
      "Epoch [5/10], Step [2620/5530], Train Loss: 0.4640, Valid Loss: 0.4591\n",
      "Epoch [5/10], Step [2640/5530], Train Loss: 0.4705, Valid Loss: 0.4578\n",
      "Epoch [5/10], Step [2660/5530], Train Loss: 0.4531, Valid Loss: 0.4578\n",
      "Epoch [5/10], Step [2680/5530], Train Loss: 0.4636, Valid Loss: 0.4582\n",
      "Epoch [5/10], Step [2700/5530], Train Loss: 0.4417, Valid Loss: 0.4577\n",
      "Epoch [5/10], Step [2720/5530], Train Loss: 0.4497, Valid Loss: 0.4576\n",
      "Epoch [5/10], Step [2740/5530], Train Loss: 0.4854, Valid Loss: 0.4581\n",
      "Epoch [5/10], Step [2760/5530], Train Loss: 0.4650, Valid Loss: 0.4570\n",
      "Epoch [6/10], Step [2780/5530], Train Loss: 0.4815, Valid Loss: 0.4574\n",
      "Epoch [6/10], Step [2800/5530], Train Loss: 0.4614, Valid Loss: 0.4570\n",
      "Epoch [6/10], Step [2820/5530], Train Loss: 0.4659, Valid Loss: 0.4554\n",
      "Epoch [6/10], Step [2840/5530], Train Loss: 0.4563, Valid Loss: 0.4581\n",
      "Epoch [6/10], Step [2860/5530], Train Loss: 0.4691, Valid Loss: 0.4584\n",
      "Epoch [6/10], Step [2880/5530], Train Loss: 0.4614, Valid Loss: 0.4581\n",
      "Epoch [6/10], Step [2900/5530], Train Loss: 0.4411, Valid Loss: 0.4580\n",
      "Epoch [6/10], Step [2920/5530], Train Loss: 0.4563, Valid Loss: 0.4588\n",
      "Epoch [6/10], Step [2940/5530], Train Loss: 0.4657, Valid Loss: 0.4588\n",
      "Epoch [6/10], Step [2960/5530], Train Loss: 0.4743, Valid Loss: 0.4569\n",
      "Epoch [6/10], Step [2980/5530], Train Loss: 0.4636, Valid Loss: 0.4553\n",
      "Epoch [6/10], Step [3000/5530], Train Loss: 0.4513, Valid Loss: 0.4565\n",
      "Epoch [6/10], Step [3020/5530], Train Loss: 0.4602, Valid Loss: 0.4574\n",
      "Epoch [6/10], Step [3040/5530], Train Loss: 0.4776, Valid Loss: 0.4576\n",
      "Epoch [6/10], Step [3060/5530], Train Loss: 0.4702, Valid Loss: 0.4560\n",
      "Epoch [6/10], Step [3080/5530], Train Loss: 0.4748, Valid Loss: 0.4566\n",
      "Epoch [6/10], Step [3100/5530], Train Loss: 0.4420, Valid Loss: 0.4553\n",
      "Epoch [6/10], Step [3120/5530], Train Loss: 0.4545, Valid Loss: 0.4560\n",
      "Epoch [6/10], Step [3140/5530], Train Loss: 0.4523, Valid Loss: 0.4575\n",
      "Epoch [6/10], Step [3160/5530], Train Loss: 0.4563, Valid Loss: 0.4556\n",
      "Epoch [6/10], Step [3180/5530], Train Loss: 0.4705, Valid Loss: 0.4567\n",
      "Epoch [6/10], Step [3200/5530], Train Loss: 0.4822, Valid Loss: 0.4568\n",
      "Epoch [6/10], Step [3220/5530], Train Loss: 0.4541, Valid Loss: 0.4570\n",
      "Epoch [6/10], Step [3240/5530], Train Loss: 0.4433, Valid Loss: 0.4565\n",
      "Epoch [6/10], Step [3260/5530], Train Loss: 0.4629, Valid Loss: 0.4550\n",
      "Epoch [6/10], Step [3280/5530], Train Loss: 0.4734, Valid Loss: 0.4585\n",
      "Epoch [6/10], Step [3300/5530], Train Loss: 0.4502, Valid Loss: 0.4565\n",
      "Epoch [7/10], Step [3320/5530], Train Loss: 0.4531, Valid Loss: 0.4560\n",
      "Epoch [7/10], Step [3340/5530], Train Loss: 0.4319, Valid Loss: 0.4570\n",
      "Epoch [7/10], Step [3360/5530], Train Loss: 0.4693, Valid Loss: 0.4568\n",
      "Epoch [7/10], Step [3380/5530], Train Loss: 0.4543, Valid Loss: 0.4557\n",
      "Epoch [7/10], Step [3400/5530], Train Loss: 0.4685, Valid Loss: 0.4550\n",
      "Epoch [7/10], Step [3420/5530], Train Loss: 0.4599, Valid Loss: 0.4559\n",
      "Epoch [7/10], Step [3440/5530], Train Loss: 0.4543, Valid Loss: 0.4579\n",
      "Epoch [7/10], Step [3460/5530], Train Loss: 0.4592, Valid Loss: 0.4574\n",
      "Epoch [7/10], Step [3480/5530], Train Loss: 0.4627, Valid Loss: 0.4549\n",
      "Epoch [7/10], Step [3500/5530], Train Loss: 0.4530, Valid Loss: 0.4560\n",
      "Epoch [7/10], Step [3520/5530], Train Loss: 0.4533, Valid Loss: 0.4588\n",
      "Epoch [7/10], Step [3540/5530], Train Loss: 0.4835, Valid Loss: 0.4567\n",
      "Epoch [7/10], Step [3560/5530], Train Loss: 0.4515, Valid Loss: 0.4559\n",
      "Epoch [7/10], Step [3580/5530], Train Loss: 0.4587, Valid Loss: 0.4557\n",
      "Epoch [7/10], Step [3600/5530], Train Loss: 0.4553, Valid Loss: 0.4585\n",
      "Epoch [7/10], Step [3620/5530], Train Loss: 0.4638, Valid Loss: 0.4548\n",
      "Epoch [7/10], Step [3640/5530], Train Loss: 0.4661, Valid Loss: 0.4550\n",
      "Epoch [7/10], Step [3660/5530], Train Loss: 0.4566, Valid Loss: 0.4555\n",
      "Epoch [7/10], Step [3680/5530], Train Loss: 0.4456, Valid Loss: 0.4541\n",
      "Epoch [7/10], Step [3700/5530], Train Loss: 0.4462, Valid Loss: 0.4542\n",
      "Epoch [7/10], Step [3720/5530], Train Loss: 0.4499, Valid Loss: 0.4541\n",
      "Epoch [7/10], Step [3740/5530], Train Loss: 0.4462, Valid Loss: 0.4555\n",
      "Epoch [7/10], Step [3760/5530], Train Loss: 0.4606, Valid Loss: 0.4538\n",
      "Epoch [7/10], Step [3780/5530], Train Loss: 0.4594, Valid Loss: 0.4544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [3800/5530], Train Loss: 0.4783, Valid Loss: 0.4551\n",
      "Epoch [7/10], Step [3820/5530], Train Loss: 0.4559, Valid Loss: 0.4553\n",
      "Epoch [7/10], Step [3840/5530], Train Loss: 0.4579, Valid Loss: 0.4544\n",
      "Epoch [7/10], Step [3860/5530], Train Loss: 0.4468, Valid Loss: 0.4564\n",
      "Epoch [8/10], Step [3880/5530], Train Loss: 0.4863, Valid Loss: 0.4576\n",
      "Epoch [8/10], Step [3900/5530], Train Loss: 0.4762, Valid Loss: 0.4552\n",
      "Epoch [8/10], Step [3920/5530], Train Loss: 0.4419, Valid Loss: 0.4572\n",
      "Epoch [8/10], Step [3940/5530], Train Loss: 0.4675, Valid Loss: 0.4551\n",
      "Epoch [8/10], Step [3960/5530], Train Loss: 0.4881, Valid Loss: 0.4541\n",
      "Epoch [8/10], Step [3980/5530], Train Loss: 0.4669, Valid Loss: 0.4553\n",
      "Epoch [8/10], Step [4000/5530], Train Loss: 0.4522, Valid Loss: 0.4545\n",
      "Epoch [8/10], Step [4020/5530], Train Loss: 0.4483, Valid Loss: 0.4546\n",
      "Epoch [8/10], Step [4040/5530], Train Loss: 0.4585, Valid Loss: 0.4552\n",
      "Epoch [8/10], Step [4060/5530], Train Loss: 0.4571, Valid Loss: 0.4553\n",
      "Epoch [8/10], Step [4080/5530], Train Loss: 0.4286, Valid Loss: 0.4564\n",
      "Epoch [8/10], Step [4100/5530], Train Loss: 0.4472, Valid Loss: 0.4586\n",
      "Epoch [8/10], Step [4120/5530], Train Loss: 0.4602, Valid Loss: 0.4565\n",
      "Epoch [8/10], Step [4140/5530], Train Loss: 0.4780, Valid Loss: 0.4549\n",
      "Epoch [8/10], Step [4160/5530], Train Loss: 0.4517, Valid Loss: 0.4567\n",
      "Epoch [8/10], Step [4180/5530], Train Loss: 0.4577, Valid Loss: 0.4560\n",
      "Epoch [8/10], Step [4200/5530], Train Loss: 0.4678, Valid Loss: 0.4568\n",
      "Epoch [8/10], Step [4220/5530], Train Loss: 0.4680, Valid Loss: 0.4582\n",
      "Epoch [8/10], Step [4240/5530], Train Loss: 0.4503, Valid Loss: 0.4557\n",
      "Epoch [8/10], Step [4260/5530], Train Loss: 0.4399, Valid Loss: 0.4574\n",
      "Epoch [8/10], Step [4280/5530], Train Loss: 0.4875, Valid Loss: 0.4562\n",
      "Epoch [8/10], Step [4300/5530], Train Loss: 0.4688, Valid Loss: 0.4570\n",
      "Epoch [8/10], Step [4320/5530], Train Loss: 0.4353, Valid Loss: 0.4555\n",
      "Epoch [8/10], Step [4340/5530], Train Loss: 0.4550, Valid Loss: 0.4539\n",
      "Epoch [8/10], Step [4360/5530], Train Loss: 0.4634, Valid Loss: 0.4567\n",
      "Epoch [8/10], Step [4380/5530], Train Loss: 0.4470, Valid Loss: 0.4551\n",
      "Epoch [8/10], Step [4400/5530], Train Loss: 0.4434, Valid Loss: 0.4540\n",
      "Epoch [8/10], Step [4420/5530], Train Loss: 0.4514, Valid Loss: 0.4557\n",
      "Epoch [9/10], Step [4440/5530], Train Loss: 0.4683, Valid Loss: 0.4560\n",
      "Epoch [9/10], Step [4460/5530], Train Loss: 0.4690, Valid Loss: 0.4567\n",
      "Epoch [9/10], Step [4480/5530], Train Loss: 0.4355, Valid Loss: 0.4562\n",
      "Epoch [9/10], Step [4500/5530], Train Loss: 0.4700, Valid Loss: 0.4552\n",
      "Epoch [9/10], Step [4520/5530], Train Loss: 0.4537, Valid Loss: 0.4555\n",
      "Epoch [9/10], Step [4540/5530], Train Loss: 0.4549, Valid Loss: 0.4570\n",
      "Epoch [9/10], Step [4560/5530], Train Loss: 0.4451, Valid Loss: 0.4536\n",
      "Epoch [9/10], Step [4580/5530], Train Loss: 0.4253, Valid Loss: 0.4549\n",
      "Epoch [9/10], Step [4600/5530], Train Loss: 0.4524, Valid Loss: 0.4554\n",
      "Epoch [9/10], Step [4620/5530], Train Loss: 0.4451, Valid Loss: 0.4570\n",
      "Epoch [9/10], Step [4640/5530], Train Loss: 0.4587, Valid Loss: 0.4552\n",
      "Epoch [9/10], Step [4660/5530], Train Loss: 0.4579, Valid Loss: 0.4547\n",
      "Epoch [9/10], Step [4680/5530], Train Loss: 0.4620, Valid Loss: 0.4554\n",
      "Epoch [9/10], Step [4700/5530], Train Loss: 0.4450, Valid Loss: 0.4578\n",
      "Epoch [9/10], Step [4720/5530], Train Loss: 0.4564, Valid Loss: 0.4578\n",
      "Epoch [9/10], Step [4740/5530], Train Loss: 0.4834, Valid Loss: 0.4562\n",
      "Epoch [9/10], Step [4760/5530], Train Loss: 0.4453, Valid Loss: 0.4598\n",
      "Epoch [9/10], Step [4780/5530], Train Loss: 0.4552, Valid Loss: 0.4569\n",
      "Epoch [9/10], Step [4800/5530], Train Loss: 0.4656, Valid Loss: 0.4587\n",
      "Epoch [9/10], Step [4820/5530], Train Loss: 0.4748, Valid Loss: 0.4568\n",
      "Epoch [9/10], Step [4840/5530], Train Loss: 0.4618, Valid Loss: 0.4548\n",
      "Epoch [9/10], Step [4860/5530], Train Loss: 0.4628, Valid Loss: 0.4537\n",
      "Epoch [9/10], Step [4880/5530], Train Loss: 0.4489, Valid Loss: 0.4558\n",
      "Epoch [9/10], Step [4900/5530], Train Loss: 0.4505, Valid Loss: 0.4549\n",
      "Epoch [9/10], Step [4920/5530], Train Loss: 0.4315, Valid Loss: 0.4558\n",
      "Epoch [9/10], Step [4940/5530], Train Loss: 0.4570, Valid Loss: 0.4539\n",
      "Epoch [9/10], Step [4960/5530], Train Loss: 0.4434, Valid Loss: 0.4533\n",
      "Epoch [10/10], Step [4980/5530], Train Loss: 0.4544, Valid Loss: 0.4563\n",
      "Epoch [10/10], Step [5000/5530], Train Loss: 0.4514, Valid Loss: 0.4562\n",
      "Epoch [10/10], Step [5020/5530], Train Loss: 0.4451, Valid Loss: 0.4551\n",
      "Epoch [10/10], Step [5040/5530], Train Loss: 0.4435, Valid Loss: 0.4560\n",
      "Epoch [10/10], Step [5060/5530], Train Loss: 0.4887, Valid Loss: 0.4537\n",
      "Epoch [10/10], Step [5080/5530], Train Loss: 0.4447, Valid Loss: 0.4555\n",
      "Epoch [10/10], Step [5100/5530], Train Loss: 0.4712, Valid Loss: 0.4553\n",
      "Epoch [10/10], Step [5120/5530], Train Loss: 0.4754, Valid Loss: 0.4559\n",
      "Epoch [10/10], Step [5140/5530], Train Loss: 0.4446, Valid Loss: 0.4536\n",
      "Epoch [10/10], Step [5160/5530], Train Loss: 0.4574, Valid Loss: 0.4536\n",
      "Epoch [10/10], Step [5180/5530], Train Loss: 0.4404, Valid Loss: 0.4539\n",
      "Epoch [10/10], Step [5200/5530], Train Loss: 0.4609, Valid Loss: 0.4556\n",
      "Epoch [10/10], Step [5220/5530], Train Loss: 0.4431, Valid Loss: 0.4561\n",
      "Epoch [10/10], Step [5240/5530], Train Loss: 0.4560, Valid Loss: 0.4561\n",
      "Epoch [10/10], Step [5260/5530], Train Loss: 0.4629, Valid Loss: 0.4537\n",
      "Epoch [10/10], Step [5280/5530], Train Loss: 0.4408, Valid Loss: 0.4538\n",
      "Epoch [10/10], Step [5300/5530], Train Loss: 0.4602, Valid Loss: 0.4527\n",
      "Epoch [10/10], Step [5320/5530], Train Loss: 0.4512, Valid Loss: 0.4557\n",
      "Epoch [10/10], Step [5340/5530], Train Loss: 0.4643, Valid Loss: 0.4527\n",
      "Epoch [10/10], Step [5360/5530], Train Loss: 0.4551, Valid Loss: 0.4537\n",
      "Epoch [10/10], Step [5380/5530], Train Loss: 0.4486, Valid Loss: 0.4551\n",
      "Epoch [10/10], Step [5400/5530], Train Loss: 0.4490, Valid Loss: 0.4553\n",
      "Epoch [10/10], Step [5420/5530], Train Loss: 0.4470, Valid Loss: 0.4537\n",
      "Epoch [10/10], Step [5440/5530], Train Loss: 0.4575, Valid Loss: 0.4540\n",
      "Epoch [10/10], Step [5460/5530], Train Loss: 0.4401, Valid Loss: 0.4546\n",
      "Epoch [10/10], Step [5480/5530], Train Loss: 0.4386, Valid Loss: 0.4548\n",
      "Epoch [10/10], Step [5500/5530], Train Loss: 0.4697, Valid Loss: 0.4538\n",
      "Epoch [10/10], Step [5520/5530], Train Loss: 0.4512, Valid Loss: 0.4538\n",
      "Finished Training\n",
      "Epoch [1/10], Step [20/5530], Train Loss: 0.7140, Valid Loss: 0.6945\n",
      "Epoch [1/10], Step [40/5530], Train Loss: 0.7049, Valid Loss: 0.7016\n",
      "Epoch [1/10], Step [60/5530], Train Loss: 0.7064, Valid Loss: 0.6875\n",
      "Epoch [1/10], Step [80/5530], Train Loss: 0.6971, Valid Loss: 0.6826\n",
      "Epoch [1/10], Step [100/5530], Train Loss: 0.7042, Valid Loss: 0.6823\n",
      "Epoch [1/10], Step [120/5530], Train Loss: 0.6950, Valid Loss: 0.6768\n",
      "Epoch [1/10], Step [140/5530], Train Loss: 0.6873, Valid Loss: 0.6792\n",
      "Epoch [1/10], Step [160/5530], Train Loss: 0.6841, Valid Loss: 0.6775\n",
      "Epoch [1/10], Step [180/5530], Train Loss: 0.6871, Valid Loss: 0.6762\n",
      "Epoch [1/10], Step [200/5530], Train Loss: 0.6855, Valid Loss: 0.6745\n",
      "Epoch [1/10], Step [220/5530], Train Loss: 0.6849, Valid Loss: 0.6694\n",
      "Epoch [1/10], Step [240/5530], Train Loss: 0.6811, Valid Loss: 0.6622\n",
      "Epoch [1/10], Step [260/5530], Train Loss: 0.6816, Valid Loss: 0.6638\n",
      "Epoch [1/10], Step [280/5530], Train Loss: 0.6877, Valid Loss: 0.6633\n",
      "Epoch [1/10], Step [300/5530], Train Loss: 0.6715, Valid Loss: 0.6642\n",
      "Epoch [1/10], Step [320/5530], Train Loss: 0.6881, Valid Loss: 0.6651\n",
      "Epoch [1/10], Step [340/5530], Train Loss: 0.6718, Valid Loss: 0.6573\n",
      "Epoch [1/10], Step [360/5530], Train Loss: 0.6670, Valid Loss: 0.6606\n",
      "Epoch [1/10], Step [380/5530], Train Loss: 0.6661, Valid Loss: 0.6551\n",
      "Epoch [1/10], Step [400/5530], Train Loss: 0.6700, Valid Loss: 0.6531\n",
      "Epoch [1/10], Step [420/5530], Train Loss: 0.6584, Valid Loss: 0.6542\n",
      "Epoch [1/10], Step [440/5530], Train Loss: 0.6670, Valid Loss: 0.6510\n",
      "Epoch [1/10], Step [460/5530], Train Loss: 0.6511, Valid Loss: 0.6453\n",
      "Epoch [1/10], Step [480/5530], Train Loss: 0.6532, Valid Loss: 0.6496\n",
      "Epoch [1/10], Step [500/5530], Train Loss: 0.6553, Valid Loss: 0.6447\n",
      "Epoch [1/10], Step [520/5530], Train Loss: 0.6495, Valid Loss: 0.6435\n",
      "Epoch [1/10], Step [540/5530], Train Loss: 0.6642, Valid Loss: 0.6435\n",
      "Epoch [2/10], Step [560/5530], Train Loss: 0.6500, Valid Loss: 0.6428\n",
      "Epoch [2/10], Step [580/5530], Train Loss: 0.6534, Valid Loss: 0.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [600/5530], Train Loss: 0.6590, Valid Loss: 0.6367\n",
      "Epoch [2/10], Step [620/5530], Train Loss: 0.6518, Valid Loss: 0.6386\n",
      "Epoch [2/10], Step [640/5530], Train Loss: 0.6457, Valid Loss: 0.6271\n",
      "Epoch [2/10], Step [660/5530], Train Loss: 0.6441, Valid Loss: 0.6357\n",
      "Epoch [2/10], Step [680/5530], Train Loss: 0.6423, Valid Loss: 0.6309\n",
      "Epoch [2/10], Step [700/5530], Train Loss: 0.6418, Valid Loss: 0.6253\n",
      "Epoch [2/10], Step [720/5530], Train Loss: 0.6416, Valid Loss: 0.6302\n",
      "Epoch [2/10], Step [740/5530], Train Loss: 0.6316, Valid Loss: 0.6290\n",
      "Epoch [2/10], Step [760/5530], Train Loss: 0.6417, Valid Loss: 0.6298\n",
      "Epoch [2/10], Step [780/5530], Train Loss: 0.6301, Valid Loss: 0.6231\n",
      "Epoch [2/10], Step [800/5530], Train Loss: 0.6392, Valid Loss: 0.6205\n",
      "Epoch [2/10], Step [820/5530], Train Loss: 0.6336, Valid Loss: 0.6188\n",
      "Epoch [2/10], Step [840/5530], Train Loss: 0.6235, Valid Loss: 0.6208\n",
      "Epoch [2/10], Step [860/5530], Train Loss: 0.6317, Valid Loss: 0.6209\n",
      "Epoch [2/10], Step [880/5530], Train Loss: 0.6302, Valid Loss: 0.6173\n",
      "Epoch [2/10], Step [900/5530], Train Loss: 0.6245, Valid Loss: 0.6153\n",
      "Epoch [2/10], Step [920/5530], Train Loss: 0.6235, Valid Loss: 0.6096\n",
      "Epoch [2/10], Step [940/5530], Train Loss: 0.6196, Valid Loss: 0.6030\n",
      "Epoch [2/10], Step [960/5530], Train Loss: 0.6149, Valid Loss: 0.6045\n",
      "Epoch [2/10], Step [980/5530], Train Loss: 0.6146, Valid Loss: 0.6061\n",
      "Epoch [2/10], Step [1000/5530], Train Loss: 0.6020, Valid Loss: 0.5997\n",
      "Epoch [2/10], Step [1020/5530], Train Loss: 0.6107, Valid Loss: 0.6021\n",
      "Epoch [2/10], Step [1040/5530], Train Loss: 0.6118, Valid Loss: 0.6015\n",
      "Epoch [2/10], Step [1060/5530], Train Loss: 0.6199, Valid Loss: 0.5955\n",
      "Epoch [2/10], Step [1080/5530], Train Loss: 0.6036, Valid Loss: 0.5962\n",
      "Epoch [2/10], Step [1100/5530], Train Loss: 0.6124, Valid Loss: 0.6002\n",
      "Epoch [3/10], Step [1120/5530], Train Loss: 0.6024, Valid Loss: 0.5951\n",
      "Epoch [3/10], Step [1140/5530], Train Loss: 0.5939, Valid Loss: 0.5905\n",
      "Epoch [3/10], Step [1160/5530], Train Loss: 0.5926, Valid Loss: 0.5867\n",
      "Epoch [3/10], Step [1180/5530], Train Loss: 0.5975, Valid Loss: 0.5869\n",
      "Epoch [3/10], Step [1200/5530], Train Loss: 0.5826, Valid Loss: 0.5871\n",
      "Epoch [3/10], Step [1220/5530], Train Loss: 0.5931, Valid Loss: 0.5872\n",
      "Epoch [3/10], Step [1240/5530], Train Loss: 0.5758, Valid Loss: 0.5818\n",
      "Epoch [3/10], Step [1260/5530], Train Loss: 0.5857, Valid Loss: 0.5808\n",
      "Epoch [3/10], Step [1280/5530], Train Loss: 0.6037, Valid Loss: 0.5780\n",
      "Epoch [3/10], Step [1300/5530], Train Loss: 0.5897, Valid Loss: 0.5818\n",
      "Epoch [3/10], Step [1320/5530], Train Loss: 0.5853, Valid Loss: 0.5756\n",
      "Epoch [3/10], Step [1340/5530], Train Loss: 0.5762, Valid Loss: 0.5752\n",
      "Epoch [3/10], Step [1360/5530], Train Loss: 0.5656, Valid Loss: 0.5762\n",
      "Epoch [3/10], Step [1380/5530], Train Loss: 0.5776, Valid Loss: 0.5706\n",
      "Epoch [3/10], Step [1400/5530], Train Loss: 0.5768, Valid Loss: 0.5691\n",
      "Epoch [3/10], Step [1420/5530], Train Loss: 0.5789, Valid Loss: 0.5662\n",
      "Epoch [3/10], Step [1440/5530], Train Loss: 0.5741, Valid Loss: 0.5655\n",
      "Epoch [3/10], Step [1460/5530], Train Loss: 0.5761, Valid Loss: 0.5598\n",
      "Epoch [3/10], Step [1480/5530], Train Loss: 0.5633, Valid Loss: 0.5610\n",
      "Epoch [3/10], Step [1500/5530], Train Loss: 0.5680, Valid Loss: 0.5544\n",
      "Epoch [3/10], Step [1520/5530], Train Loss: 0.5575, Valid Loss: 0.5582\n",
      "Epoch [3/10], Step [1540/5530], Train Loss: 0.5730, Valid Loss: 0.5523\n",
      "Epoch [3/10], Step [1560/5530], Train Loss: 0.5602, Valid Loss: 0.5556\n",
      "Epoch [3/10], Step [1580/5530], Train Loss: 0.5582, Valid Loss: 0.5502\n",
      "Epoch [3/10], Step [1600/5530], Train Loss: 0.5504, Valid Loss: 0.5462\n",
      "Epoch [3/10], Step [1620/5530], Train Loss: 0.5538, Valid Loss: 0.5449\n",
      "Epoch [3/10], Step [1640/5530], Train Loss: 0.5580, Valid Loss: 0.5433\n",
      "Epoch [4/10], Step [1660/5530], Train Loss: 0.5597, Valid Loss: 0.5421\n",
      "Epoch [4/10], Step [1680/5530], Train Loss: 0.5570, Valid Loss: 0.5418\n",
      "Epoch [4/10], Step [1700/5530], Train Loss: 0.5528, Valid Loss: 0.5424\n",
      "Epoch [4/10], Step [1720/5530], Train Loss: 0.5443, Valid Loss: 0.5378\n",
      "Epoch [4/10], Step [1740/5530], Train Loss: 0.5430, Valid Loss: 0.5381\n",
      "Epoch [4/10], Step [1760/5530], Train Loss: 0.5392, Valid Loss: 0.5331\n",
      "Epoch [4/10], Step [1780/5530], Train Loss: 0.5382, Valid Loss: 0.5311\n",
      "Epoch [4/10], Step [1800/5530], Train Loss: 0.5374, Valid Loss: 0.5315\n",
      "Epoch [4/10], Step [1820/5530], Train Loss: 0.5342, Valid Loss: 0.5246\n",
      "Epoch [4/10], Step [1840/5530], Train Loss: 0.5407, Valid Loss: 0.5259\n",
      "Epoch [4/10], Step [1860/5530], Train Loss: 0.5310, Valid Loss: 0.5249\n",
      "Epoch [4/10], Step [1880/5530], Train Loss: 0.5236, Valid Loss: 0.5217\n",
      "Epoch [4/10], Step [1900/5530], Train Loss: 0.5185, Valid Loss: 0.5231\n",
      "Epoch [4/10], Step [1920/5530], Train Loss: 0.5247, Valid Loss: 0.5227\n",
      "Epoch [4/10], Step [1940/5530], Train Loss: 0.5275, Valid Loss: 0.5179\n",
      "Epoch [4/10], Step [1960/5530], Train Loss: 0.5095, Valid Loss: 0.5141\n",
      "Epoch [4/10], Step [1980/5530], Train Loss: 0.5168, Valid Loss: 0.5134\n",
      "Epoch [4/10], Step [2000/5530], Train Loss: 0.5217, Valid Loss: 0.5129\n",
      "Epoch [4/10], Step [2020/5530], Train Loss: 0.5330, Valid Loss: 0.5151\n",
      "Epoch [4/10], Step [2040/5530], Train Loss: 0.5139, Valid Loss: 0.5072\n",
      "Epoch [4/10], Step [2060/5530], Train Loss: 0.5185, Valid Loss: 0.5075\n",
      "Epoch [4/10], Step [2080/5530], Train Loss: 0.5016, Valid Loss: 0.5060\n",
      "Epoch [4/10], Step [2100/5530], Train Loss: 0.5374, Valid Loss: 0.5078\n",
      "Epoch [4/10], Step [2120/5530], Train Loss: 0.5274, Valid Loss: 0.5123\n",
      "Epoch [4/10], Step [2140/5530], Train Loss: 0.5119, Valid Loss: 0.5033\n",
      "Epoch [4/10], Step [2160/5530], Train Loss: 0.5101, Valid Loss: 0.5060\n",
      "Epoch [4/10], Step [2180/5530], Train Loss: 0.4989, Valid Loss: 0.5041\n",
      "Epoch [4/10], Step [2200/5530], Train Loss: 0.5071, Valid Loss: 0.4972\n",
      "Epoch [5/10], Step [2220/5530], Train Loss: 0.5004, Valid Loss: 0.4999\n",
      "Epoch [5/10], Step [2240/5530], Train Loss: 0.5057, Valid Loss: 0.4980\n",
      "Epoch [5/10], Step [2260/5530], Train Loss: 0.5074, Valid Loss: 0.4974\n",
      "Epoch [5/10], Step [2280/5530], Train Loss: 0.4937, Valid Loss: 0.4977\n",
      "Epoch [5/10], Step [2300/5530], Train Loss: 0.5095, Valid Loss: 0.4965\n",
      "Epoch [5/10], Step [2320/5530], Train Loss: 0.5065, Valid Loss: 0.4953\n",
      "Epoch [5/10], Step [2340/5530], Train Loss: 0.5111, Valid Loss: 0.4930\n",
      "Epoch [5/10], Step [2360/5530], Train Loss: 0.5091, Valid Loss: 0.4923\n",
      "Epoch [5/10], Step [2380/5530], Train Loss: 0.5089, Valid Loss: 0.4898\n",
      "Epoch [5/10], Step [2400/5530], Train Loss: 0.4936, Valid Loss: 0.4927\n",
      "Epoch [5/10], Step [2420/5530], Train Loss: 0.4935, Valid Loss: 0.4898\n",
      "Epoch [5/10], Step [2440/5530], Train Loss: 0.4990, Valid Loss: 0.4876\n",
      "Epoch [5/10], Step [2460/5530], Train Loss: 0.4744, Valid Loss: 0.4888\n",
      "Epoch [5/10], Step [2480/5530], Train Loss: 0.4838, Valid Loss: 0.4879\n",
      "Epoch [5/10], Step [2500/5530], Train Loss: 0.4897, Valid Loss: 0.4880\n",
      "Epoch [5/10], Step [2520/5530], Train Loss: 0.4805, Valid Loss: 0.4852\n",
      "Epoch [5/10], Step [2540/5530], Train Loss: 0.4983, Valid Loss: 0.4844\n",
      "Epoch [5/10], Step [2560/5530], Train Loss: 0.4822, Valid Loss: 0.4833\n",
      "Epoch [5/10], Step [2580/5530], Train Loss: 0.4815, Valid Loss: 0.4817\n",
      "Epoch [5/10], Step [2600/5530], Train Loss: 0.4886, Valid Loss: 0.4810\n",
      "Epoch [5/10], Step [2620/5530], Train Loss: 0.5011, Valid Loss: 0.4806\n",
      "Epoch [5/10], Step [2640/5530], Train Loss: 0.4986, Valid Loss: 0.4774\n",
      "Epoch [5/10], Step [2660/5530], Train Loss: 0.4831, Valid Loss: 0.4846\n",
      "Epoch [5/10], Step [2680/5530], Train Loss: 0.5066, Valid Loss: 0.4801\n",
      "Epoch [5/10], Step [2700/5530], Train Loss: 0.4780, Valid Loss: 0.4809\n",
      "Epoch [5/10], Step [2720/5530], Train Loss: 0.4796, Valid Loss: 0.4763\n",
      "Epoch [5/10], Step [2740/5530], Train Loss: 0.4767, Valid Loss: 0.4781\n",
      "Epoch [5/10], Step [2760/5530], Train Loss: 0.5036, Valid Loss: 0.4754\n",
      "Epoch [6/10], Step [2780/5530], Train Loss: 0.4757, Valid Loss: 0.4756\n",
      "Epoch [6/10], Step [2800/5530], Train Loss: 0.4711, Valid Loss: 0.4762\n",
      "Epoch [6/10], Step [2820/5530], Train Loss: 0.4913, Valid Loss: 0.4774\n",
      "Epoch [6/10], Step [2840/5530], Train Loss: 0.4780, Valid Loss: 0.4740\n",
      "Epoch [6/10], Step [2860/5530], Train Loss: 0.4888, Valid Loss: 0.4754\n",
      "Epoch [6/10], Step [2880/5530], Train Loss: 0.4790, Valid Loss: 0.4729\n",
      "Epoch [6/10], Step [2900/5530], Train Loss: 0.4834, Valid Loss: 0.4733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [2920/5530], Train Loss: 0.4726, Valid Loss: 0.4724\n",
      "Epoch [6/10], Step [2940/5530], Train Loss: 0.4772, Valid Loss: 0.4712\n",
      "Epoch [6/10], Step [2960/5530], Train Loss: 0.4856, Valid Loss: 0.4700\n",
      "Epoch [6/10], Step [2980/5530], Train Loss: 0.4829, Valid Loss: 0.4705\n",
      "Epoch [6/10], Step [3000/5530], Train Loss: 0.4744, Valid Loss: 0.4716\n",
      "Epoch [6/10], Step [3020/5530], Train Loss: 0.4839, Valid Loss: 0.4702\n",
      "Epoch [6/10], Step [3040/5530], Train Loss: 0.4747, Valid Loss: 0.4716\n",
      "Epoch [6/10], Step [3060/5530], Train Loss: 0.4729, Valid Loss: 0.4708\n",
      "Epoch [6/10], Step [3080/5530], Train Loss: 0.4895, Valid Loss: 0.4708\n",
      "Epoch [6/10], Step [3100/5530], Train Loss: 0.4829, Valid Loss: 0.4711\n",
      "Epoch [6/10], Step [3120/5530], Train Loss: 0.4680, Valid Loss: 0.4709\n",
      "Epoch [6/10], Step [3140/5530], Train Loss: 0.4853, Valid Loss: 0.4702\n",
      "Epoch [6/10], Step [3160/5530], Train Loss: 0.4693, Valid Loss: 0.4686\n",
      "Epoch [6/10], Step [3180/5530], Train Loss: 0.4780, Valid Loss: 0.4687\n",
      "Epoch [6/10], Step [3200/5530], Train Loss: 0.4880, Valid Loss: 0.4706\n",
      "Epoch [6/10], Step [3220/5530], Train Loss: 0.4949, Valid Loss: 0.4699\n",
      "Epoch [6/10], Step [3240/5530], Train Loss: 0.4863, Valid Loss: 0.4703\n",
      "Epoch [6/10], Step [3260/5530], Train Loss: 0.4855, Valid Loss: 0.4666\n",
      "Epoch [6/10], Step [3280/5530], Train Loss: 0.4625, Valid Loss: 0.4704\n",
      "Epoch [6/10], Step [3300/5530], Train Loss: 0.4680, Valid Loss: 0.4683\n",
      "Epoch [7/10], Step [3320/5530], Train Loss: 0.4814, Valid Loss: 0.4673\n",
      "Epoch [7/10], Step [3340/5530], Train Loss: 0.4644, Valid Loss: 0.4662\n",
      "Epoch [7/10], Step [3360/5530], Train Loss: 0.4652, Valid Loss: 0.4661\n",
      "Epoch [7/10], Step [3380/5530], Train Loss: 0.4648, Valid Loss: 0.4695\n",
      "Epoch [7/10], Step [3400/5530], Train Loss: 0.4858, Valid Loss: 0.4676\n",
      "Epoch [7/10], Step [3420/5530], Train Loss: 0.4840, Valid Loss: 0.4669\n",
      "Epoch [7/10], Step [3440/5530], Train Loss: 0.4626, Valid Loss: 0.4671\n",
      "Epoch [7/10], Step [3460/5530], Train Loss: 0.4735, Valid Loss: 0.4652\n",
      "Epoch [7/10], Step [3480/5530], Train Loss: 0.4734, Valid Loss: 0.4649\n",
      "Epoch [7/10], Step [3500/5530], Train Loss: 0.4624, Valid Loss: 0.4660\n",
      "Epoch [7/10], Step [3520/5530], Train Loss: 0.4860, Valid Loss: 0.4663\n",
      "Epoch [7/10], Step [3540/5530], Train Loss: 0.4899, Valid Loss: 0.4657\n",
      "Epoch [7/10], Step [3560/5530], Train Loss: 0.4706, Valid Loss: 0.4657\n",
      "Epoch [7/10], Step [3580/5530], Train Loss: 0.4741, Valid Loss: 0.4633\n",
      "Epoch [7/10], Step [3600/5530], Train Loss: 0.4732, Valid Loss: 0.4652\n",
      "Epoch [7/10], Step [3620/5530], Train Loss: 0.4727, Valid Loss: 0.4654\n",
      "Epoch [7/10], Step [3640/5530], Train Loss: 0.4970, Valid Loss: 0.4653\n",
      "Epoch [7/10], Step [3660/5530], Train Loss: 0.4684, Valid Loss: 0.4642\n",
      "Epoch [7/10], Step [3680/5530], Train Loss: 0.4608, Valid Loss: 0.4645\n",
      "Epoch [7/10], Step [3700/5530], Train Loss: 0.4727, Valid Loss: 0.4639\n",
      "Epoch [7/10], Step [3720/5530], Train Loss: 0.4709, Valid Loss: 0.4633\n",
      "Epoch [7/10], Step [3740/5530], Train Loss: 0.4741, Valid Loss: 0.4638\n",
      "Epoch [7/10], Step [3760/5530], Train Loss: 0.4613, Valid Loss: 0.4629\n",
      "Epoch [7/10], Step [3780/5530], Train Loss: 0.4722, Valid Loss: 0.4646\n",
      "Epoch [7/10], Step [3800/5530], Train Loss: 0.4881, Valid Loss: 0.4631\n",
      "Epoch [7/10], Step [3820/5530], Train Loss: 0.4640, Valid Loss: 0.4628\n",
      "Epoch [7/10], Step [3840/5530], Train Loss: 0.4761, Valid Loss: 0.4650\n",
      "Epoch [7/10], Step [3860/5530], Train Loss: 0.4621, Valid Loss: 0.4640\n",
      "Epoch [8/10], Step [3880/5530], Train Loss: 0.4782, Valid Loss: 0.4637\n",
      "Epoch [8/10], Step [3900/5530], Train Loss: 0.4518, Valid Loss: 0.4644\n",
      "Epoch [8/10], Step [3920/5530], Train Loss: 0.4614, Valid Loss: 0.4645\n",
      "Epoch [8/10], Step [3940/5530], Train Loss: 0.4562, Valid Loss: 0.4641\n",
      "Epoch [8/10], Step [3960/5530], Train Loss: 0.4906, Valid Loss: 0.4629\n",
      "Epoch [8/10], Step [3980/5530], Train Loss: 0.4697, Valid Loss: 0.4636\n",
      "Epoch [8/10], Step [4000/5530], Train Loss: 0.4757, Valid Loss: 0.4628\n",
      "Epoch [8/10], Step [4020/5530], Train Loss: 0.4643, Valid Loss: 0.4632\n",
      "Epoch [8/10], Step [4040/5530], Train Loss: 0.4711, Valid Loss: 0.4630\n",
      "Epoch [8/10], Step [4060/5530], Train Loss: 0.4600, Valid Loss: 0.4629\n",
      "Epoch [8/10], Step [4080/5530], Train Loss: 0.4833, Valid Loss: 0.4633\n",
      "Epoch [8/10], Step [4100/5530], Train Loss: 0.4774, Valid Loss: 0.4627\n",
      "Epoch [8/10], Step [4120/5530], Train Loss: 0.4723, Valid Loss: 0.4627\n",
      "Epoch [8/10], Step [4140/5530], Train Loss: 0.4631, Valid Loss: 0.4610\n",
      "Epoch [8/10], Step [4160/5530], Train Loss: 0.4695, Valid Loss: 0.4617\n",
      "Epoch [8/10], Step [4180/5530], Train Loss: 0.4579, Valid Loss: 0.4623\n",
      "Epoch [8/10], Step [4200/5530], Train Loss: 0.4658, Valid Loss: 0.4620\n",
      "Epoch [8/10], Step [4220/5530], Train Loss: 0.4845, Valid Loss: 0.4617\n",
      "Epoch [8/10], Step [4240/5530], Train Loss: 0.4839, Valid Loss: 0.4625\n",
      "Epoch [8/10], Step [4260/5530], Train Loss: 0.4608, Valid Loss: 0.4637\n",
      "Epoch [8/10], Step [4280/5530], Train Loss: 0.4864, Valid Loss: 0.4609\n",
      "Epoch [8/10], Step [4300/5530], Train Loss: 0.4529, Valid Loss: 0.4621\n",
      "Epoch [8/10], Step [4320/5530], Train Loss: 0.4676, Valid Loss: 0.4621\n",
      "Epoch [8/10], Step [4340/5530], Train Loss: 0.4795, Valid Loss: 0.4609\n",
      "Epoch [8/10], Step [4360/5530], Train Loss: 0.4701, Valid Loss: 0.4612\n",
      "Epoch [8/10], Step [4380/5530], Train Loss: 0.4726, Valid Loss: 0.4620\n",
      "Epoch [8/10], Step [4400/5530], Train Loss: 0.4539, Valid Loss: 0.4624\n",
      "Epoch [8/10], Step [4420/5530], Train Loss: 0.4614, Valid Loss: 0.4614\n",
      "Epoch [9/10], Step [4440/5530], Train Loss: 0.4669, Valid Loss: 0.4606\n",
      "Epoch [9/10], Step [4460/5530], Train Loss: 0.4649, Valid Loss: 0.4604\n",
      "Epoch [9/10], Step [4480/5530], Train Loss: 0.4661, Valid Loss: 0.4623\n",
      "Epoch [9/10], Step [4500/5530], Train Loss: 0.4706, Valid Loss: 0.4597\n",
      "Epoch [9/10], Step [4520/5530], Train Loss: 0.4695, Valid Loss: 0.4612\n",
      "Epoch [9/10], Step [4540/5530], Train Loss: 0.4688, Valid Loss: 0.4632\n",
      "Epoch [9/10], Step [4560/5530], Train Loss: 0.4643, Valid Loss: 0.4602\n",
      "Epoch [9/10], Step [4580/5530], Train Loss: 0.4640, Valid Loss: 0.4603\n",
      "Epoch [9/10], Step [4600/5530], Train Loss: 0.4755, Valid Loss: 0.4607\n",
      "Epoch [9/10], Step [4620/5530], Train Loss: 0.4679, Valid Loss: 0.4596\n",
      "Epoch [9/10], Step [4640/5530], Train Loss: 0.4684, Valid Loss: 0.4608\n",
      "Epoch [9/10], Step [4660/5530], Train Loss: 0.4572, Valid Loss: 0.4601\n",
      "Epoch [9/10], Step [4680/5530], Train Loss: 0.4677, Valid Loss: 0.4597\n",
      "Epoch [9/10], Step [4700/5530], Train Loss: 0.4822, Valid Loss: 0.4611\n",
      "Epoch [9/10], Step [4720/5530], Train Loss: 0.4521, Valid Loss: 0.4600\n",
      "Epoch [9/10], Step [4740/5530], Train Loss: 0.4629, Valid Loss: 0.4612\n",
      "Epoch [9/10], Step [4760/5530], Train Loss: 0.4580, Valid Loss: 0.4628\n",
      "Epoch [9/10], Step [4780/5530], Train Loss: 0.4779, Valid Loss: 0.4604\n",
      "Epoch [9/10], Step [4800/5530], Train Loss: 0.4546, Valid Loss: 0.4607\n",
      "Epoch [9/10], Step [4820/5530], Train Loss: 0.4611, Valid Loss: 0.4617\n",
      "Epoch [9/10], Step [4840/5530], Train Loss: 0.4716, Valid Loss: 0.4600\n",
      "Epoch [9/10], Step [4860/5530], Train Loss: 0.4556, Valid Loss: 0.4595\n",
      "Epoch [9/10], Step [4880/5530], Train Loss: 0.4689, Valid Loss: 0.4604\n",
      "Epoch [9/10], Step [4900/5530], Train Loss: 0.4670, Valid Loss: 0.4594\n",
      "Epoch [9/10], Step [4920/5530], Train Loss: 0.4865, Valid Loss: 0.4608\n",
      "Epoch [9/10], Step [4940/5530], Train Loss: 0.4575, Valid Loss: 0.4619\n",
      "Epoch [9/10], Step [4960/5530], Train Loss: 0.4461, Valid Loss: 0.4610\n",
      "Epoch [10/10], Step [4980/5530], Train Loss: 0.4566, Valid Loss: 0.4581\n",
      "Epoch [10/10], Step [5000/5530], Train Loss: 0.4743, Valid Loss: 0.4602\n",
      "Epoch [10/10], Step [5020/5530], Train Loss: 0.4703, Valid Loss: 0.4600\n",
      "Epoch [10/10], Step [5040/5530], Train Loss: 0.4618, Valid Loss: 0.4579\n",
      "Epoch [10/10], Step [5060/5530], Train Loss: 0.4745, Valid Loss: 0.4625\n",
      "Epoch [10/10], Step [5080/5530], Train Loss: 0.4557, Valid Loss: 0.4591\n",
      "Epoch [10/10], Step [5100/5530], Train Loss: 0.4707, Valid Loss: 0.4582\n",
      "Epoch [10/10], Step [5120/5530], Train Loss: 0.4661, Valid Loss: 0.4589\n",
      "Epoch [10/10], Step [5140/5530], Train Loss: 0.4597, Valid Loss: 0.4578\n",
      "Epoch [10/10], Step [5160/5530], Train Loss: 0.4609, Valid Loss: 0.4594\n",
      "Epoch [10/10], Step [5180/5530], Train Loss: 0.4515, Valid Loss: 0.4592\n",
      "Epoch [10/10], Step [5200/5530], Train Loss: 0.4651, Valid Loss: 0.4581\n",
      "Epoch [10/10], Step [5220/5530], Train Loss: 0.4514, Valid Loss: 0.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [5240/5530], Train Loss: 0.4464, Valid Loss: 0.4589\n",
      "Epoch [10/10], Step [5260/5530], Train Loss: 0.4703, Valid Loss: 0.4579\n",
      "Epoch [10/10], Step [5280/5530], Train Loss: 0.4462, Valid Loss: 0.4613\n",
      "Epoch [10/10], Step [5300/5530], Train Loss: 0.4716, Valid Loss: 0.4598\n",
      "Epoch [10/10], Step [5320/5530], Train Loss: 0.4643, Valid Loss: 0.4590\n",
      "Epoch [10/10], Step [5340/5530], Train Loss: 0.4779, Valid Loss: 0.4591\n",
      "Epoch [10/10], Step [5360/5530], Train Loss: 0.4756, Valid Loss: 0.4606\n",
      "Epoch [10/10], Step [5380/5530], Train Loss: 0.4794, Valid Loss: 0.4597\n",
      "Epoch [10/10], Step [5400/5530], Train Loss: 0.4599, Valid Loss: 0.4592\n",
      "Epoch [10/10], Step [5420/5530], Train Loss: 0.4586, Valid Loss: 0.4588\n",
      "Epoch [10/10], Step [5440/5530], Train Loss: 0.4402, Valid Loss: 0.4597\n",
      "Epoch [10/10], Step [5460/5530], Train Loss: 0.4774, Valid Loss: 0.4584\n",
      "Epoch [10/10], Step [5480/5530], Train Loss: 0.4617, Valid Loss: 0.4589\n",
      "Epoch [10/10], Step [5500/5530], Train Loss: 0.4864, Valid Loss: 0.4600\n",
      "Epoch [10/10], Step [5520/5530], Train Loss: 0.4690, Valid Loss: 0.4593\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tunning\n",
    "avg_training_loss = list()\n",
    "avg_val_loss = list()\n",
    "timer = list()\n",
    "\n",
    "\n",
    "for learning_rate in [0.001, 0.0003, 0.0001]:\n",
    "\n",
    "    running_loss = 0.0\n",
    "    global_step = 0\n",
    "    eval_every = 20\n",
    "    num_epochs = 10\n",
    "    lr = learning_rate\n",
    "    total_step = len(train_loader)*num_epochs\n",
    "\n",
    "    net = Net().to(device)\n",
    "    m = nn.Sigmoid()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            net.train()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            '''Training of the model'''\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)  \n",
    "            loss = criterion(m(outputs), labels.float())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            '''Evaluating the model every x steps'''\n",
    "            if global_step % eval_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    net.eval()\n",
    "                    val_running_loss = 0.0\n",
    "                    for val_inputs, val_labels in valid_loader:\n",
    "                        val_outputs = net(val_inputs)\n",
    "\n",
    "                        val_loss = criterion(m(val_outputs), val_labels.float())\n",
    "                        val_running_loss += val_loss.item()\n",
    "\n",
    "                    average_train_loss = running_loss / eval_every\n",
    "                    average_val_loss = val_running_loss / len(valid_loader)\n",
    "\n",
    "                    # ...log the running loss\n",
    "                    writer.add_scalar(\n",
    "                        f'training loss {num_epochs}', average_train_loss, global_step)\n",
    "\n",
    "                    # ...log the running loss\n",
    "                    writer.add_scalar(\n",
    "                        f'validation loss {num_epochs}', average_val_loss, global_step)\n",
    "\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, average_train_loss, average_val_loss))\n",
    "\n",
    "                    running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    avg_training_loss.append(average_train_loss)\n",
    "    avg_val_loss.append(average_val_loss)\n",
    "    timer.append(time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4479095220565796, 0.4511846587061882, 0.4689651608467102]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4518907074448016, 0.45376535028004816, 0.4592733308136892]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[897.3858160972595, 877.1827170848846, 858.0115337371826]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test csv\n",
    "data_path = './pa2_data/part1_data/test.csv'\n",
    "test = pd.read_csv(data_path)\n",
    "test.index = range(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "# find out grayscale pictures\n",
    "for i in range(len(test)):\n",
    "    if default_loader(file_test[i]).size()[0] != 3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop([1191, 1200])\n",
    "file_test = test['imdbId']\n",
    "file_test.index = range(len(file_test))\n",
    "\n",
    "file_test = [str(i)+\".jpg\" for i in file_test]\n",
    "file_test = [os.path.join(\"./pa2_data/part1_data/images/\", i) for i in file_test ]\n",
    "labels_test = np.array(test[['Action', 'Adventure', 'Animation', 'Comedy', 'Drama',\n",
    "       'Horror', 'Romance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MovieDataset(file_test, labels_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classification_report for theta:  0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.72      0.42       413\n",
      "           1       0.24      0.26      0.25       254\n",
      "           2       0.26      0.32      0.29       148\n",
      "           3       0.45      0.92      0.60       772\n",
      "           4       0.58      0.99      0.73      1151\n",
      "           5       0.32      0.43      0.36       259\n",
      "           6       0.28      0.72      0.41       417\n",
      "\n",
      "   micro avg       0.42      0.78      0.54      3414\n",
      "   macro avg       0.35      0.62      0.44      3414\n",
      "weighted avg       0.42      0.78      0.54      3414\n",
      " samples avg       0.43      0.79      0.53      3414\n",
      "\n",
      "the classification_report for theta:  0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.58      0.43       413\n",
      "           1       0.27      0.19      0.22       254\n",
      "           2       0.30      0.28      0.29       148\n",
      "           3       0.50      0.81      0.62       772\n",
      "           4       0.58      0.98      0.73      1151\n",
      "           5       0.34      0.31      0.32       259\n",
      "           6       0.33      0.51      0.40       417\n",
      "\n",
      "   micro avg       0.47      0.69      0.56      3414\n",
      "   macro avg       0.38      0.52      0.43      3414\n",
      "weighted avg       0.45      0.69      0.54      3414\n",
      " samples avg       0.50      0.71      0.55      3414\n",
      "\n",
      "the classification_report for theta:  0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.42      0.40       413\n",
      "           1       0.31      0.13      0.18       254\n",
      "           2       0.34      0.24      0.28       148\n",
      "           3       0.54      0.66      0.60       772\n",
      "           4       0.59      0.97      0.73      1151\n",
      "           5       0.41      0.21      0.28       259\n",
      "           6       0.36      0.27      0.30       417\n",
      "\n",
      "   micro avg       0.51      0.59      0.55      3414\n",
      "   macro avg       0.42      0.41      0.40      3414\n",
      "weighted avg       0.48      0.59      0.51      3414\n",
      " samples avg       0.55      0.62      0.54      3414\n",
      "\n",
      "the classification_report for theta:  0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.11      0.17       413\n",
      "           1       0.33      0.01      0.02       254\n",
      "           2       0.44      0.11      0.18       148\n",
      "           3       0.63      0.39      0.48       772\n",
      "           4       0.60      0.91      0.73      1151\n",
      "           5       0.38      0.02      0.04       259\n",
      "           6       0.17      0.00      0.00       417\n",
      "\n",
      "   micro avg       0.59      0.42      0.49      3414\n",
      "   macro avg       0.42      0.22      0.23      3414\n",
      "weighted avg       0.49      0.42      0.39      3414\n",
      " samples avg       0.61      0.45      0.49      3414\n",
      "\n",
      "the classification_report for theta:  0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.07      0.12       413\n",
      "           1       0.00      0.00      0.00       254\n",
      "           2       0.42      0.07      0.13       148\n",
      "           3       0.65      0.33      0.43       772\n",
      "           4       0.60      0.88      0.72      1151\n",
      "           5       0.40      0.02      0.03       259\n",
      "           6       0.00      0.00      0.00       417\n",
      "\n",
      "   micro avg       0.60      0.38      0.47      3414\n",
      "   macro avg       0.36      0.20      0.20      3414\n",
      "weighted avg       0.45      0.38      0.36      3414\n",
      " samples avg       0.61      0.42      0.48      3414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def eval(model, test_loader, theta):\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            #model.eval()\n",
    "            outputs = net(inputs)\n",
    "            for i in range(len(outputs)):\n",
    "                predict = list()\n",
    "                raw = outputs[i].tolist()\n",
    "        \n",
    "                output = [(float(i)-min(raw))/(max(raw)-min(raw)) for i in raw]\n",
    "                #print(output)\n",
    "                #print(output)\n",
    "                for j in range(7):\n",
    "                    if (output[j] < theta):\n",
    "                        predict.append(0)\n",
    "                    else:\n",
    "                        predict.append(1)\n",
    "                        \n",
    "                y_pred.append(predict)\n",
    "                y_test.append(labels[i].tolist())\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "for theta in [0.3, 0.5, 0.8, 0.9]:\n",
    "#for theta in [1]:\n",
    "    print(\"the classification_report for theta: \", theta)\n",
    "    eval(net, test_loader, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.5 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prediction csv\n",
    "data_path = './pa2_data/part1_data/submission.csv'\n",
    "submission = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_submission = submission['imdbId']\n",
    "\n",
    "file_submission = [str(i)+\".jpg\" for i in file_submission]\n",
    "file_submission = [os.path.join(\"./pa2_data/part1_data/images\", i) for i in file_submission ]\n",
    "labels_submission = list()\n",
    "for i in range(len(file_submission)):\n",
    "    labels_submission.append([0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = MovieDataset(file_submission, labels)\n",
    "submit_loader = DataLoader(submit_data, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "# From the classification report shown above, i think theta should be 0.3 to get the optimal f1 score\n",
    "y_pred = []\n",
    "count = 0\n",
    "\n",
    "\n",
    "for inputs, labels in submit_loader:\n",
    "    #model.eval()\n",
    "    outputs = net(inputs)\n",
    "    for i in range(len(outputs)):\n",
    "        predict = list()\n",
    "        raw = outputs[i].tolist()\n",
    "\n",
    "        output = [(float(i)-min(raw))/(max(raw)-min(raw)) for i in raw]\n",
    "\n",
    "        for j in range(7):\n",
    "            if (output[j] < 0.3):\n",
    "                predict.append(0)\n",
    "            else:\n",
    "                predict.append(1)\n",
    "\n",
    "        y_pred.append(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_pred)\n",
    "#prediction = prediction.iloc[:, 1:7]\n",
    "#prediction.colomns = []\n",
    "#prediction.rename(columns = {'1':'Action'}, inplace = True)\n",
    "prediction.columns = ['Action', 'Adventure', 'Animation', 'Comedy', 'Drama',\n",
    "       'Horror', 'Romance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Romance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2960930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>305396</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1413489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>3704050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>477253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>371606</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>392364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1794725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbId  Action  Adventure  Animation  Comedy  Drama  Horror  Romance\n",
       "0    2960930       0          0          0       0      1       1        0\n",
       "1    1295071       1          0          0       1      1       0        0\n",
       "2     239441       1          0          0       1      1       0        1\n",
       "3     305396       1          0          0       1      1       0        0\n",
       "4    1413489       1          0          0       1      1       0        1\n",
       "..       ...     ...        ...        ...     ...    ...     ...      ...\n",
       "586  3704050       1          0          0       1      1       1        0\n",
       "587   477253       0          0          0       1      1       0        1\n",
       "588   371606       1          0          0       0      1       1        0\n",
       "589   392364       0          0          0       1      1       0        1\n",
       "590  1794725       1          0          0       0      1       1        0\n",
       "\n",
       "[591 rows x 8 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['imdbId'] = submission['imdbId']\n",
    "prediction = prediction[['imdbId', 'Action', 'Adventure', 'Animation', 'Comedy', 'Drama',\n",
    "       'Horror', 'Romance']]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
